<!doctype html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="author" content="Adam Novotny">
    <meta name="description" content="This alphabetically sorted collection of AI, ML, and data resources was last updated on 3/26/2021. AdaBoost: Fits a sequence of weak learners on...">
    <title>Machine Learning Notes | ANotes</title>
    <link rel="icon" type="image/png" sizes="32x32" href="https://adamnovotny.com/theme/images/favicon.png">
<link rel="canonical" href="https://adamnovotny.com/blog/machine-learning-notes.html">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:regular,bold,italic,thin,light,bolditalic,black,medium&amp;lang=en">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.0.13/css/all.css" integrity="sha384-DNOHZ68U8hZfKXOrtjWvjxusGo9WQnrNx2sqG0tfsghAvtVlRW3tvkXWZh58N9jp" crossorigin="anonymous">
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-+0n0xVW2eSR5OomGNYDnhzAbDsOXxcvSN1TPprVMTNDbiYZCxYbOOl7+AMvyTG2x" crossorigin="anonymous">
    <link rel="stylesheet" href="https://adamnovotny.com/theme/css/blog.css">
</head>

<body>
    <nav class="navbar navbar-expand-lg navbar-light">
        <div class="container-fluid">
          <a class="navbar-brand" href="https://adamnovotny.com">
            <img src="https://adamnovotny.com/theme/images/adamnovotny_logo.png" alt="">
          </a>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
            <span class="navbar-toggler-icon"></span>
          </button>
          <div class="collapse navbar-collapse" id="navbarSupportedContent">
            <ul class="navbar-nav me-auto mb-2 mb-lg-0">
              <li class="nav-item dropdown">
                <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
                  Articles
                </a>
                <ul class="dropdown-menu" aria-labelledby="navbarDropdown">
                  <li><a class="dropdown-item" href="https://adamnovotny.com/category/finance.html">Finance <i class="fas fa-chart-line fa-md"></i></a></li>
                  <li><a class="dropdown-item" href="https://adamnovotny.com/category/machine-learning.html">Machine Learning <i class="fas fa-table fa-md"></i></a></li>
                  <li><a class="dropdown-item" href="https://adamnovotny.com/category/programming.html">Programming <i class="fas fa-laptop fa-md"></i></a></li>
                  <li><a class="dropdown-item" href="https://adamnovotny.com/category/random.html">Random Thoughts <i class="fas fa-random fa-md"></i></a></li>
                </ul>
              </li>
              <li class="nav-item dropdown">
                <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
                  About
                </a>
                <ul class="dropdown-menu" aria-labelledby="navbarDropdown">
                  <li><a class="dropdown-item" href="https://github.com/adamnovotnycom">Github <i class="fab fa-github fa-md"></i></a></li>
                  <li><a class="dropdown-item" href="https://www.linkedin.com/in/adamnovotnycom">LinkedIn <i class="fab fa-linkedin fa-md"></i></a></li>
                  <li><a class="dropdown-item" href="https://medium.com/@adamnovotnycom">Medium <i class="fab fa-medium fa-md"></i></a></li>
                  <li><a class="dropdown-item" href="https://twitter.com/adamnovotnycom">Twitter <i class="fab fa-twitter fa-md"></i></a></li>
                </ul>
              </li>
            </ul>
          </div>
        </div>
      </nav>
      

<main class="container">
    <div class="row">
        <div class="col"></div>
        <div class="col-md-9">
    
            <div class="blog-post">
            <h2 class="blog-post-title">Machine Learning Notes</h2>
            <p class="blog-post-meta" >2020-12-23</p>
            <p>This alphabetically sorted collection of AI, ML, and data resources was last updated on 3/26/2021.</p>

<p><a href="/theme/images/1*mobq_8Cwq6J59oN07-aKwA.png.png"><img src="/theme/images/1*mobq_8Cwq6J59oN07-aKwA.png.png" alt="ML breakdown: Supervised + Unsupervised + RL" style="width: 100%" loading="lazy"></a>
<ul>
<li><a href="https://scikit-learn.org/stable/modules/ensemble.html#adaboost" target="_blank">AdaBoost</a>: Fits a sequence of weak learners on repeatadly modified data. The modifications are based on errors made by previous learners.</li>
<li><a href="https://online.stat.psu.edu/stat503/lesson/3/3.1#paragraph--294" target="_blank">Analysis of variance ANOVA</a></li>
<li><a href="https://www.nature.com/articles/s43586-020-00001-2" target="_blank">Bayesian modelling</a></li>
<li><a href="https://towardsdatascience.com/beta-distribution-intuition-examples-and-derivation-cf00f4db57af" target="_blank">Beta Distribution</a>: probability distribution on probabilities bounded [0, 1]</li>
<li><a href="https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html" target="_blank">Classification algorithms comparison</a></li>
<a href="/theme/images/1*GkUw2SIWy0Fl2rKd6cIPmg.png.png"><img src="/theme/images/1*GkUw2SIWy0Fl2rKd6cIPmg.png.png" alt="Classifier comparison: scikit-learn.org" style="width: 100%" loading="lazy"></a>
<li>Confidence interval: <a href="https://online.stat.psu.edu/stat501/node/644" target="_blank">linear regression coefficient</a></li>
<a href="/theme/images/1*hQ5pabjmSByQSC5O4r_uRw.png.png"><img src="/theme/images/1*hQ5pabjmSByQSC5O4r_uRw.png.png" alt="t-interval for slope parameter beta_1" style="width: 100%" loading="lazy"></a>
<li><a href="https://a16z.com/2020/10/15/the-emerging-architectures-for-modern-data-infrastructure/" target="_blank">Data and ML Infrastructure (a16z)</a></li>
<a href="/theme/images/1*LYBSxf0MPcERPzkEJlk9Cw.png.png"><img src="/theme/images/1*LYBSxf0MPcERPzkEJlk9Cw.png.png" alt="A Unified Data Infra" style="width: 100%" loading="lazy"></a>
<a href="/theme/images/1*MqMX4k5IupAK9T9vKs5h8g.png.png"><img src="/theme/images/1*MqMX4k5IupAK9T9vKs5h8g.png.png" alt="AI and ML Blueprint" style="width: 100%" loading="lazy"></a>
<li><a href="https://scikit-learn.org/stable/modules/mixture.html#estimation-algorithm-expectation-maximization" target="_blank">Expectation-maximization (EM)</a>: assumes random components and computes for each point a probability of being generated by each component of the model. Then iteratively tweaks the parameters to maximize the likelihood of the data given those assignments. Example: <a href="https://scikit-learn.org/stable/modules/mixture.html#gaussian-mixture" target="_blank">Gaussian Mixture</a></li>
<li><a href="https://online.stat.psu.edu/stat501/lesson/6/6.2#paragraph--785" target="_blank">F-statistic</a>: determines whether to reject a full model (F) in favor of a reduced (R) model. Reject full model if F is large — or equivalently if its associated p-value is small</li>
<a href="/theme/images/1*7Vz6m3tqtLAvxF_Xqe2JAQ.png.png"><img src="/theme/images/1*7Vz6m3tqtLAvxF_Xqe2JAQ.png.png" alt="F* statistic equation" style="width: 100%" loading="lazy"></a>
<li><a href="https://scikit-learn.org/stable/modules/ensemble.html#gradient-boosting" target="_blank">Gradient Boosting</a>: optimization of arbitrary differentiable loss functions. — Risk of overfitting</li>
<li><a href="https://scikit-learn.org/stable/modules/neighbors.html#nearest-neighbors-classification" target="_blank">KNN</a>: + Simple, flexible, naturally handles multiple classes. — Slow at scale, sensitive to feature scaling and irrelevant features</li>
<li><a href="https://scikit-learn.org/stable/modules/clustering.html#k-means" target="_blank">K-means</a>: aims to choose centroids that minimize the inertia, or within-cluster sum-of-squares criterion. Use the <a href="https://www.scikit-yb.org/en/latest/api/cluster/elbow.html" target="_blank">“elbow” method</a> to identify the right number of means</li>
<li><a href="https://scikit-learn.org/stable/modules/linear_model.html#lasso" target="_blank">Lasso</a>: linear model regularization technique with tendency to prefer solutions with fewer non-zero coefficients</li>
<a href="/theme/images/1*bvk1Esh-TGPCIub2ggNzQg.png.png"><img src="/theme/images/1*bvk1Esh-TGPCIub2ggNzQg.png.png" alt="Lasso equation" style="width: 100%" loading="lazy"></a>
<li><a href="https://scikit-learn.org/stable/auto_examples/model_selection/plot_learning_curve.html#plotting-learning-curves" target="_blank">Learning Curve</a></li>
<a href="/theme/images/1*fz1sqw361u7Y_D1G-aDEmw.png.png"><img src="/theme/images/1*fz1sqw361u7Y_D1G-aDEmw.png.png" alt="Learning Curve example" style="width: 100%" loading="lazy"></a>
<li><a href="https://sklearn.org/modules/lda_qda.html#mathematical-formulation-of-the-lda-and-qda-classifiers" target="_blank">Linear Discriminant Analysis (LDA)</a>: A classifier with a linear decision boundary, generated by fitting class conditional densities to the data and using Bayes’ rule. The model fits a Gaussian density to each class, assuming that all classes share the same covariance matrix.</li>
<li>Linear regression<a href="https://online.stat.psu.edu/stat500/lesson/9/9.2/9.2.3#paragraph--3265" target="_blank"> assumptions</a> (LINE): 1) Linearity, 2) Independence of errors, 3) Normality of errors, 4) Equal variances. Tests of assumptions: i) plot each feature on x-axis vs y_error, ii) plot y_predicted on x-axis vs y_error, iii) histogram of errors</li>
<li>
Means
<ol>
<li><a href="https://mathworld.wolfram.com/ArithmeticMean.html" target="_blank">Arithmetic</a></li>
<li><a href="https://mathworld.wolfram.com/GeometricMean.html" target="_blank">Geometric</a>: used in finance to calculate average growth rates and is referred to as the compounded annual growth rate</li>
<li><a href="https://mathworld.wolfram.com/HarmonicMean.html" target="_blank">Harmonic: </a> used in finance to average multiples like the price-earnings ratio because it gives equal weight to each data point. Using a weighted arithmetic mean to average these ratios would give greater weight to high data points than low data points because price-earnings ratios aren't price-normalized while the earnings are equalized</li>
</ol>
</li>
<li><a href="https://rmartinshort.jimdofree.com/2019/02/17/overfitting-bias-variance-and-leaning-curves/" target="_blank">Overfitting, bias-variance and learning curves</a>. Overfitting (high variance) options: more data, increase regularization, or decrease model complexity</li>
<li><a href="https://online.stat.psu.edu/stat462/node/195/" target="_blank">Overspecified</a> model: can be used for prediction of the label, but should not be used to ascribe the effect of a feature on the label</li>
<li><a href="https://scikit-learn.org/stable/modules/decomposition.html#pca" target="_blank">PCA</a>: transform data using k vectors that minimize the perpendicular distance to points. PCA can be also thought of as an <a href="https://online.stat.psu.edu/stat505/lesson/11/11.2" target="_blank">eigenvalue/engenvector decomposition</a>. <a href="https://www.cs.princeton.edu/picasso/mats/PCA-Tutorial-Intuition_jp.pdf" target="_blank">Intuition paper</a></li>
<li><a href="https://en.wikipedia.org/wiki/Pearson_correlation_coefficient" target="_blank">Pearson’s correlation coefficient</a></li>
<a href="/theme/images/1*qtdPV-XQhTYACKS7beLDpg.jpeg.png"><img src="/theme/images/1*qtdPV-XQhTYACKS7beLDpg.jpeg.png" alt="Correlation formula" style="width: 100%" loading="lazy"></a>
<li><a href="https://scikit-learn.org/stable/modules/model_evaluation.html#receiver-operating-characteristic-roc" target="_blank">Receiver operating characteristic (ROC)</a>: relates true positive rate (y-axis) and false positive rate (x-axis). A <a href="https://en.wikipedia.org/wiki/Precision_and_recall#Recall" target="_blank">confusion</a> matrix defines TPR = TP / (TP + FN) and FPR = FP / (FP + TN)</li>
<li>
<a href="https://medium.com/@srowen/common-probability-distributions-347e6b945ce4" target="_blank">Probability distributions</a>
<a href="/theme/images/Bf8a4LtHWOrJ.png"><img src="/theme/images/Bf8a4LtHWOrJ.png" alt="Correlation formula" style="width: 100%" loading="lazy"></a>
</li>
<li><a href="https://scikit-learn.org/stable/modules/naive_bayes.html#naive-bayes" target="_blank">Naive Bayes</a></li>
<li><a href="http://cecas.clemson.edu/~ahoover/ece854/lecture-notes/lecture-normeqs.pdf" target="_blank">Normal Equation</a></li>
<a href="/theme/images/1*i0ylsCBDeVY5rFlGa9AYWg.png.png"><img src="/theme/images/1*i0ylsCBDeVY5rFlGa9AYWg.png.png" alt="Normal equation" style="width: 100%" loading="lazy"></a>
<li><a href="https://scikit-learn.org/stable/modules/ensemble.html#random-forests" target="_blank">Random Forests</a>: each tree is built using a sample of rows (with replacement) from training set. + Less prone to overfitting</li>
<li><a href="https://scikit-learn.org/stable/modules/linear_model.html#ridge-regression-and-classification" target="_blank">Ridge Regression</a> regularization: imposes a penalty on the size of the coefficients</li>
<a href="/theme/images/1*fekJIBmDHMoU2zQ6wVmQkA.png.png"><img src="/theme/images/1*fekJIBmDHMoU2zQ6wVmQkA.png.png" alt="Ridge Regression" style="width: 100%" loading="lazy"></a>
<li><a href="https://scikit-learn.org/stable/modules/model_evaluation.html#r2-score" target="_blank">R2</a>: strength of a linear relationship. Could be 0 for nonlinear relationships. Never worsens with more features</li>
<li><a href="https://online.stat.psu.edu/stat500/lesson/1/1.5/1.5.3#paragraph--3051" target="_blank">Sample variance</a>: divided by n-1 to achieve an unbiased estimator because 1 degree of freedom is used to estimate b0</li>
<li><a href="https://www.kaggle.com/residentmario/oversampling-with-smote-and-adasyn" target="_blank">SMOTE</a> algorithm is parameterized with k_neighbors. Generate and place a new point on the vector between a minority class point and one of its nearest neighbors, located [0, 1] percent of the way from the original point</li>
<li><a href="https://lamfo-unb.github.io/2019/04/21/Sorting-algorithms" target="_blank">Sorting algorithms</a></li>
<a href="/theme/images/rO1H18bCodMa.png"><img src="/theme/images/rO1H18bCodMa.png" alt="Ridge Regression" style="width: 100%" loading="lazy"></a>
<li>SQL tricks
<ol>
<li><a href="https://docs.microsoft.com/en-us/sql/t-sql/functions/row-number-transact-sql?view=sql-server-ver15#d-using-row_number-with-partition" target="_blank">window functions, row_number() and partition()</a></li>
<li><a href="https://docs.microsoft.com/en-us/sql/t-sql/language-elements/coalesce-transact-sql?view=sql-server-ver15" target="_blank">COALESCE()</a>: evaluates the arguments in order and returns the current value of the first expression that initially doesn’t evaluate to NULL</li>
</ol>
</li>
<li><a href="https://scikit-learn.org/stable/modules/svm.html#svm-classification" target="_blank">SVM</a>: Effective in high dimensional spaces (or when number of dimensions &gt; number of examples). SVMs do not directly provide probability estimates
</li>
<li>Stochastic gradient descent cost function</li>
<a href="/theme/images/1*_6C1R-IamnPtIo0jLOoblw.png.png"><img src="/theme/images/1*_6C1R-IamnPtIo0jLOoblw.png.png" alt="Stochastic gradient descent cost function" style="width: 100%" loading="lazy"></a>
<li><a href="https://online.stat.psu.edu/stat555/node/36/" target="_blank">T-test</a></li>
<a href="/theme/images/1*R1ysZ-ofSr5wXwE0_emXiQ.png.png"><img src="/theme/images/1*R1ysZ-ofSr5wXwE0_emXiQ.png.png" alt="T-test formula" style="width: 100%" loading="lazy"></a>
<li><a href="https://scikit-learn.org/stable/auto_examples/model_selection/plot_validation_curve.html#plotting-validation-curves" target="_blank">Validation curve</a></li>
<a href="/theme/images/1*HVM4sFhGDTNE40xr5aVCiQ.png.png"><img src="/theme/images/1*HVM4sFhGDTNE40xr5aVCiQ.png.png" alt="validation curve example" style="width: 100%" loading="lazy"></a>
</ul></p>
            <a href="https://medium.com/@adamnovotnycom/machine-learning-notes-8dfcb983ff01/">Also on <i class="fab fa-medium fa-lg"></i></a>
            </div>
    
        </div>
        <div class="col"></div>
    </div>
</main>

      
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.1/dist/js/bootstrap.bundle.min.js" integrity="sha384-gtEjrD/SeCtmISkJkNUaaKMoLD0//ElJ19smozuHV6z3Iehds+3Ulb9Bn9Plx0x4" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/vue"></script>
    <script src="https://unpkg.com/axios/dist/axios.min.js"></script>
</body>


</html>