<!doctype html>
<html lang="en">
<head>
    <title>Machine Learning Tutorial #4: Deployment</title>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="description" content="Adam Novotny's website. LinkedIn, Medium, Twiter.">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, minimum-scale=1.0">
    <base href="/">
    <link rel="icon" type="image/x-icon" href="favicon.ico">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:regular,bold,italic,thin,light,bolditalic,black,medium&amp;lang=en">
    <link rel="stylesheet" href="https://fonts.googleapis.com/icon?family=Material+Icons">
    <link rel="stylesheet" href="https://code.getmdl.io/1.3.0/material.deep_purple-green.min.css" /> 
    <link rel="stylesheet" type="text/css" href="/theme/css/style.css" />
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.0.13/css/all.css" integrity="sha384-DNOHZ68U8hZfKXOrtjWvjxusGo9WQnrNx2sqG0tfsghAvtVlRW3tvkXWZh58N9jp" crossorigin="anonymous">
    <!-- <script src="https://cdn.jsdelivr.net/npm/vue/dist/vue.js"></script> -->
    <script src="https://cdn.jsdelivr.net/npm/vue"></script>
    <script src="https://unpkg.com/axios/dist/axios.min.js"></script>
    <style>
        #view-source {
            position: fixed;
            display: block;
            right: 0;
            bottom: 0;
            margin-right: 40px;
            margin-bottom: 40px;
            z-index: 900;
        }
    </style>
</head>
<body>
    <div class="demo-blog demo-blog--blogpost mdl-layout mdl-js-layout has-drawer is-upgraded">
        <main class="mdl-layout__content">

<div class="demo-back">
    <a class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--icon" href="/" title="go back" role="button">
        <i class="material-icons" role="presentation">arrow_back</i>
    </a>
</div>
<div class="demo-blog__posts mdl-grid">
    <div class="mdl-card mdl-shadow--4dp mdl-cell mdl-cell--12-col">
        <div class="mdl-card__media mdl-color-text--grey-50" style="background-image: url(https://cdn-images-1.medium.com/max/400/1*T_-rIQ8yUgPba_ezxt6ogg.png); background-repeat: no-repeat; background-size: cover;">
        <h3>Machine Learning Tutorial #4: Deployment</h3>
        </div>
        <div class="mdl-color-text--grey-700 mdl-card__supporting-text meta">
        <div>
            <strong>Adam Novotny</strong>
            <span>2018-09-02</span>
        </div>
        <div class="section-spacer"></div>
        <div>
            <a href="https://twitter.com/excitedAtom">
                <i class="material-icons" role="presentation">share</i>
                <span class="visuallyhidden">share</span>
            </a>
        </div>
        </div>
        <div class="mdl-color-text--grey-700 mdl-card__supporting-text">
            <p>Topics: Stack Selection, Heroku, Testing</p>

<p><img src="https://cdn-images-1.medium.com/max/2600/1*T_-rIQ8yUgPba_ezxt6ogg.png" alt="Machine Learning project overview. Author: Adam Novotny" style="width: 100%">
<p>In this final phase of the series, I will suggest a few options ML engineers have to deploy their code. In large organizations, this part of the project will be handled by a specialized team which is especially important when scaling is a concern. Other tutorials in this series: <a href="https://medium.com/coinmonks/machine-learning-tutorial-1-preprocessing-d90198e37577" target="_blank">#1 Preprocessing</a>, <a href="https://medium.com/coinmonks/machine-learning-tutorial-2-training-f6f735830838" target="_blank">#2 Training</a>, <a href="https://medium.com/coinmonks/machine-learning-tutorial-3-evaluation-a157f90914c9" target="_blank">#3 Evaluation</a> , #4 Deployment (this article). <a href="https://github.com/adam5ny/blogs/tree/master/ml-deployment" target="_blank">Github code</a>.</p>
<p>Stack Selection</p>
<p>The number of options to deploy ML code is numerous but I typically decide between at least the three general buckets:</p>
<ul><li>Solution provided as-a-service (e.g. Microsoft Azure Machine Learning Studio)</li></ul>
<ul><li>Serverless function (e.g. <a href="https://docs.aws.amazon.com/lambda/latest/dg/python-programming-model.html" target="_blank">AWS Lambda</a>)</li></ul>
<ul><li>Custom backend code (e.g. <a href="http://flask.pocoo.org/docs/0.12/" target="_blank">Python Flask</a> served by <a href="https://devcenter.heroku.com/articles/getting-started-with-python" target="_blank">Heroku</a>)</li></ul>
<p>As-a-service solution</p>
<p>Platforms such as Microsoft Azure Machine Learning Studio offer the full suite of tools for the entire project including preprocessing and training. Custom API endpoints are usually easy to generate and writing code is often not necessary thanks to drag-and-drop interfaces. The solutions are often well optimized for <a href="https://en.wikipedia.org/wiki/Lazy_learning" target="_blank">lazy learners</a> where evaluation is the most expensive computational step. The downside is that it is sometimes more challenging to bring in custom code (such as the final model) without going through all the project steps on the platform.</p>
<img src="https://cdn-images-1.medium.com/max/2600/1*4F3z9NovnqtOtIRWRCJn_Q.jpeg" alt="As-a-service deployment example: Microsoft Azure" style="width: 100%">
<p>Serverless function</p>
<p>Serverless functions are a good solution for inexpensive computations. AWS uses default timeout of 3 seconds for a function to complete. While timeouts can be extended, the default value is often a good general guideline when deciding about suitability. Lambda only allows 50MB of custom code to be uploaded which is generally not enough for most machine learning purposes. However, functions are well suited for fast computations such as linear regression models. Another downside is that platforms support only specific languages. In terms of Python solutions, AWS Lambda supports versions 2.7 and 3.6 only at the time of writing this article.</p>
<p>Custom backend code</p>
<p>Writing a custom backend code on platform such as Heroku or Amazon’s EC2 allows us to replicate fully the code we write on local machines. The code and server deployment can be fully customized for the type of ML algorithm we are deploying. The downside of such solutions is their operational complexity because we need to focus on many steps unrelated to ML such as security.</p>
<p>I will deploy the code on <a href="https://devcenter.heroku.com/articles/getting-started-with-python" target="_blank">Heroku</a> which offers a free tier for testing purposes. The lightweight <a href="http://flask.pocoo.org/" target="_blank">Flask framework</a> will drive the backend. The primary reason for this choice is that it allows us to reuse essentially all the code written in previous tutorials for the backend. We can install Flask with Python 3.6 and all machine learning libraries we use previously side by side.</p>
<p>The entire backend code to run the app is literally a few lines long with Flask:</p>
<pre>import pickle
import pandas as pd
from flask import Flask, jsonify, request, make_response</pre>
<pre>app = Flask(<strong>name</strong>)</pre>
<pre><a href="http://twitter.com/app" target="_blank">@app</a>.route('/forecast', methods=["POST"])
def forecast_post():
    """
    Args:
        request.data: json pandas dataframe
            example: {
                "columns": ["date", "open", "high", "low", "close",
                   "volume"],
                "index":[1, 0],
                "data": [
                   [1532390400000, 108, 108, 107, 107, 26316],
                   [1532476800000, 107, 111, 107, 110, 30702]]
            }
    """
    if request.data:
        df = pd.read_json(request.data, orient='split')
        X = preprocess(df)
        model = pickle.load(open("dtree_model.pkl", "rb"))
        y_pred = run_model(X, model)
        resp = make_response(jsonify({
           "y_pred": json.dumps(y_pred.tolist())
        }), 200)
        return resp
    else:
        return make_response(jsonify({"message": "no data"}), 400)</pre>
<ul><li>pd.read_json(…): reads data from <a href="https://en.wikipedia.org/wiki/POST_(HTTP)" target="_blank">POST request</a> which is a json object corresponding to price data formatted the same way as Yahoo finance prices (our original data source)</li></ul>
<ul><li>preprocess(…): copy of our code from the <a href="https://medium.com/coinmonks/machine-learning-tutorial-1-preprocessing-d90198e37577" target="_blank">Preprocessing</a> tutorial that manipulates raw price data into features. Importantly, the scaler used must be the exact same we used in Preprocessing so it has to be saved to pickle file first during Preprocessing and loaded from pickle now</li></ul>
<ul><li>run_model(…): loads and runs our saved final model from the <a href="https://medium.com/coinmonks/machine-learning-tutorial-2-training-f6f735830838" target="_blank">Training</a> tutorial</li></ul>
<ul><li>make_response(…): returns forecasts</li></ul>
<p>Heroku</p>
<p>Deploying our prediction code to Heroku will require that we collect at least two necessary pieces of our code from previous tutorials: the final model (saved as a pickle file) and the code from the <a href="https://medium.com/coinmonks/machine-learning-tutorial-1-preprocessing-d90198e37577" target="_blank">Preprocessing</a> tutorial that transforms the original features we collected from the real world to features our model can handle.</p>
<p>I will not go into details about how to deploy a Docker app on Heroku. There are plenty of good materials including Heroku’s documentation, which is excellent. All the necessary code to run and deploy the Docker app on Heroku is also in the <a href="https://github.com/adam5ny/blogs/tree/master/ml-deployment" target="_blank">Github </a>repo. There are a few key steps to remember:</p>
<ul><li>Save Dockerfile as Dockerfile.web which is a container of all code necessary to run the app</li></ul>
<ul><li>Deploy container using command <a href="https://devcenter.heroku.com/articles/container-registry-and-runtime" target="_blank">heroku container:push</a></li></ul>
<ul><li>Release container using command <a href="https://devcenter.heroku.com/articles/container-registry-and-runtime" target="_blank">heroku container:release</a></li></ul>
<p>At this point our code is deployed which we can test using <a href="https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=2ahUKEwjmut-U1JvdAhVKsqQKHaQUBg0QFjAAegQIBRAC&url=https%3A%2F%2Fwww.getpostman.com%2F&usg=AOvVaw1vWzpwzQOHi5ErKZnywLDR" target="_blank">Postman</a> to make a manual forecast request:</p>
<img src="https://cdn-images-1.medium.com/max/2600/1*5kvKnVEez88tZ96uTtOqjg.png" alt="" style="width: 100%">
<p>The date is represented by Unix timestamp. The first Body window consists of inputs we provide to the endpoint in the form of prices. The second window returns forecasts from the app.</p>
<p>Testing</p>
<p>To test the implementation, I will reuse the code from the Evaluation step. However, instead of making predictions locally using our sklearn model, I will use the Heroku app to predict the 691 samples from Evaluation as a batch. The goal is for our predictions we made on a local machine to perfectly match those made using our deployment stack.</p>
<p>This step is critical to ensure that we can replicate our results remotely using a pre-trained model. The testing code is also available on <a href="https://github.com/adam5ny/blogs/blob/master/ml-deployment/backend/tests/test_app.py" target="_blank">Github</a>. We confirm that the performance of our Heroku app matches the performance generated locally in the Evaluation tutorial:</p>
<img src="https://cdn-images-1.medium.com/max/2600/1*Oewaabcu926MZpC-zFFpHQ.png" alt="Tested deployment performance matches evaluation results" style="width: 100%">
<p>To conclude, the project is intended to provide an overview of the kind of thinking a data science project entails. The code should not be used in production and is provided solely for illustrative purposes. As always, I welcome all constructive feedback (positive or negative) on <a href="https://twitter.com/adam5ny" target="_blank">Twitter</a>.</p>
<p>Other tutorials in this series: <a href="https://medium.com/coinmonks/machine-learning-tutorial-1-preprocessing-d90198e37577" target="_blank">#1 Preprocessing</a>, <a href="https://medium.com/coinmonks/machine-learning-tutorial-2-training-f6f735830838" target="_blank">#2 Training</a>, <a href="https://medium.com/coinmonks/machine-learning-tutorial-3-evaluation-a157f90914c9" target="_blank">#3 Evaluation</a>, #4 Deployment (this article). <a href="https://github.com/adam5ny/blogs/tree/master/ml-deployment" target="_blank">Github code</a>.</p>
<p>Author website: <a href="https://www.adamnovotny.com/" target="_blank">adamnovotny.com</a></p></p>
            <a href="https://medium.com/@excitedAtom/machine-learning-tutorial-4-deployment-79764123e9e1/"><i class="fab fa-medium fa-lg"></i></a>
        </div>
    </div>
    <nav class="demo-nav mdl-color-text--grey-50 mdl-cell mdl-cell--12-col">
        <a href="/" class="demo-nav__button">
            <button class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--icon mdl-color--white mdl-color-text--grey-900" role="presentation">
                <i class="material-icons">arrow_back</i>
            </button>
            Newer
        </a>
    </nav>
</div>


            <footer class="mdl-mini-footer">
                <div class="mdl-mini-footer--left-section">
                    <a href="https://keybase.io/adam5ny">Keybase <i class="fab fa-keybase fa-lg"></i></a>
                    <a href="https://github.com/excitedAtom">Github <i class="fab fa-github fa-lg"></i></a>
                    <a href="https://www.linkedin.com/in/excitedAtom">LinkedIn <i class="fab fa-linkedin fa-lg"></i></a>
                    <a href="https://medium.com/@excitedAtom">Medium <i class="fab fa-medium fa-lg"></i></a>
                    <a href="/quotes/q-list.html">Quotes</a>
                    
                </div>
                <div class="mdl-mini-footer--right-section">
                    <a href="https://twitter.com/excitedAtom">Twitter <i class="fab fa-twitter fa-lg"></i></a>
                </div>
            </footer>
        </main>
        <div class="mdl-layout__obfuscator"></div>
    </div>
    <script defer src="https://code.getmdl.io/1.3.0/material.min.js"></script>
    <script src="/theme/js/main.js" defer></script>
    <script>
        (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
        (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
        m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
        })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
        ga('create', 'UA-71868344-1', 'auto');
        ga('send', 'pageview');
    </script>
</body>
<script>
    Array.prototype.forEach.call(document.querySelectorAll('.mdl-card__media'), function(el) {
        var link = el.querySelector('a');
        if(!link) {
        return;
        }
        var target = link.getAttribute('href');
        if(!target) {
        return;
        }
        el.addEventListener('click', function() {
        location.href = target;
        });
    });
</script>
</html>