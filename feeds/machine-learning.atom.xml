<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>ANotes - Machine Learning</title><link href="https://adamnovotny.com/" rel="alternate"></link><link href="https://adamnovotny.com/feeds/machine-learning.atom.xml" rel="self"></link><id>https://adamnovotny.com/</id><updated>2021-03-20T00:00:00-05:00</updated><entry><title>Google Colab and Auto-sklearn with Profiling</title><link href="https://adamnovotny.com/blog/google-colab-and-auto-sklearn-with-profiling.html" rel="alternate"></link><published>2021-03-20T00:00:00-05:00</published><updated>2021-03-20T00:00:00-05:00</updated><author><name>Adam Novotny</name></author><id>tag:adamnovotny.com,2021-03-20:/blog/google-colab-and-auto-sklearn-with-profiling.html</id><summary type="html">&lt;p&gt;This article is a follow up to my previous tutorial on how to &lt;a href="https://adamnovotny.com/blog/google-colab-and-automl-auto-sklearn-setup.html" target="_blank"&gt;setup Google Colab and auto-sklean&lt;/a&gt;. Here, I will go into more detail that shows auto-sklearn performance on an artificially created dataset. The full notebook gist can be found &lt;a href="https://gist.github.com/adamnovotnycom/ffe8e3961fe0207c64a1b9a074883e51" target="_blank"&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;First, I generated a regression dataset using &lt;a href="https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_regression.html" target="_blank"&gt;scikit …&lt;/a&gt;&lt;/p&gt;</summary><content type="html">&lt;p&gt;This article is a follow up to my previous tutorial on how to &lt;a href="https://adamnovotny.com/blog/google-colab-and-automl-auto-sklearn-setup.html" target="_blank"&gt;setup Google Colab and auto-sklean&lt;/a&gt;. Here, I will go into more detail that shows auto-sklearn performance on an artificially created dataset. The full notebook gist can be found &lt;a href="https://gist.github.com/adamnovotnycom/ffe8e3961fe0207c64a1b9a074883e51" target="_blank"&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;First, I generated a regression dataset using &lt;a href="https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_regression.html" target="_blank"&gt;scikit learn&lt;/a&gt;.&lt;/p&gt;

&lt;pre&gt;X, y, coeff = make_regression(
    n_samples=1000,
    n_features=100,
    n_informative=5,
    noise=0,
    shuffle=False,
    coef=True
)&lt;/pre&gt;

&lt;p&gt;&lt;a href="/theme/images/1*Nv5JrZA6e7M9-K_gPxsspg.jpeg.png"&gt;&lt;img src="/theme/images/1*Nv5JrZA6e7M9-K_gPxsspg.jpeg.png" alt="Subset of 100 generated features" style="width: 100%" loading="lazy"&gt;&lt;/a&gt;
&lt;p&gt;This generates a dataset with 100 numerical features where the first 5 features are informative (these are labeled as “feat_0” to “feat_4”). The rest (“feat_5” to “feat_99”) are random noise. We can see this in the scatter matrix above where only the first 5 features show a correlation with the label.&lt;/p&gt;
&lt;p&gt;We know that this is a simple regression problem which could be solved using a linear regression perfectly. However, knowing what to expect helps us to verify the performance of auto-sklearn which trains its ensemble model using the following steps:&lt;/p&gt;
&lt;pre&gt;import autosklearn.regressionautoml = autosklearn.regression.AutoSklearnRegressor(
    time_left_for_this_task=300,
    n_jobs=-1
)
automl.fit(
    X_train_transformed,
    df_train["label"]
)&lt;/pre&gt;
&lt;p&gt;I also created random categorical features which are then one-hot-encoded into a feature set “X_train_transformed“. Running the AutoSklearnRegressor for 5 minutes (time_left_for_this_task=300) produced the following expected results:&lt;/p&gt;
&lt;pre&gt;predictions = automl.predict(X_train_transformed)
r2_score(df_train["label"], predictions)&lt;/p&gt;
&lt;blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;0.999
predictions = automl.predict(X_test_transformed)
r2_score(df_test["label"], predictions)
0.999&lt;/pre&gt;
&lt;p&gt;A separate pip package &lt;a href="https://github.com/VIDA-NYU/PipelineVis" target="_blank"&gt;PipelineProfiler&lt;/a&gt; helps us visualize the steps auto-sklearn took to achieve the result:&lt;/p&gt;
&lt;a href="/theme/images/1*9ZWW9HeGqTjkan4qtd4mDQ.jpeg.png"&gt;&lt;img src="/theme/images/1*9ZWW9HeGqTjkan4qtd4mDQ.jpeg.png" alt="PipelineProfiler output" style="width: 100%" loading="lazy"&gt;&lt;/a&gt;
&lt;p&gt;Above we can see the attempts auto-sklearn made to generate the best emsemble of models within the 5 minute constraint I set. The best model found was &lt;a href="https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html" target="_blank"&gt;Liblinear SVM&lt;/a&gt;, which produced R2 of nearly 1.0. As a result, this toy ensemble model gives weight of 1.0 to just one algorithm. Libsvm Svr and Gradient boosting scored between 0.9–0.96.&lt;/p&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/blockquote&gt;</content><category term="Machine Learning"></category></entry><entry><title>Machine Learning Notes</title><link href="https://adamnovotny.com/blog/machine-learning-notes.html" rel="alternate"></link><published>2020-12-23T00:00:00-05:00</published><updated>2020-12-23T00:00:00-05:00</updated><author><name>Adam Novotny</name></author><id>tag:adamnovotny.com,2020-12-23:/blog/machine-learning-notes.html</id><summary type="html">&lt;p&gt;This alphabetically sorted collection of AI, ML, and data resources was last updated on 3/26/2021.&lt;/p&gt;

&lt;p&gt;&lt;a href="/theme/images/1*mobq_8Cwq6J59oN07-aKwA.png.png"&gt;&lt;img src="/theme/images/1*mobq_8Cwq6J59oN07-aKwA.png.png" alt="ML breakdown: Supervised + Unsupervised + RL" style="width: 100%" loading="lazy"&gt;&lt;/a&gt;
&lt;ul&gt;&lt;li&gt;&lt;a href="https://scikit-learn.org/stable/modules/ensemble.html#adaboost" target="_blank"&gt;AdaBoost&lt;/a&gt;: Fits a sequence of weak learners on repeatadly modified data. The modifications are based on errors made by previous learners.&lt;/li&gt;&lt;/ul&gt;
&lt;ul&gt;&lt;li&gt;&lt;a href="https://online.stat.psu.edu/stat503/lesson/3/3.1#paragraph--294" target="_blank"&gt;Analysis of variance ANOVA&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;ul&gt;&lt;li&gt;&lt;a href="https://www.nature.com/articles/s43586-020-00001-2" target="_blank"&gt;Bayesian modelling&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;ul&gt;&lt;li&gt;&lt;a href="https://towardsdatascience.com/beta-distribution-intuition-examples-and-derivation-cf00f4db57af" target="_blank"&gt;Beta Distribution&lt;/a&gt;: probability distribution on probabilities …&lt;/li&gt;&lt;/ul&gt;&lt;/p&gt;</summary><content type="html">&lt;p&gt;This alphabetically sorted collection of AI, ML, and data resources was last updated on 3/26/2021.&lt;/p&gt;

&lt;p&gt;&lt;a href="/theme/images/1*mobq_8Cwq6J59oN07-aKwA.png.png"&gt;&lt;img src="/theme/images/1*mobq_8Cwq6J59oN07-aKwA.png.png" alt="ML breakdown: Supervised + Unsupervised + RL" style="width: 100%" loading="lazy"&gt;&lt;/a&gt;
&lt;ul&gt;&lt;li&gt;&lt;a href="https://scikit-learn.org/stable/modules/ensemble.html#adaboost" target="_blank"&gt;AdaBoost&lt;/a&gt;: Fits a sequence of weak learners on repeatadly modified data. The modifications are based on errors made by previous learners.&lt;/li&gt;&lt;/ul&gt;
&lt;ul&gt;&lt;li&gt;&lt;a href="https://online.stat.psu.edu/stat503/lesson/3/3.1#paragraph--294" target="_blank"&gt;Analysis of variance ANOVA&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;ul&gt;&lt;li&gt;&lt;a href="https://www.nature.com/articles/s43586-020-00001-2" target="_blank"&gt;Bayesian modelling&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;ul&gt;&lt;li&gt;&lt;a href="https://towardsdatascience.com/beta-distribution-intuition-examples-and-derivation-cf00f4db57af" target="_blank"&gt;Beta Distribution&lt;/a&gt;: probability distribution on probabilities bounded [0, 1]&lt;/li&gt;&lt;/ul&gt;
&lt;ul&gt;&lt;li&gt;&lt;a href="https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html" target="_blank"&gt;Classification algorithms comparison&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;a href="/theme/images/1*GkUw2SIWy0Fl2rKd6cIPmg.png.png"&gt;&lt;img src="/theme/images/1*GkUw2SIWy0Fl2rKd6cIPmg.png.png" alt="Classifier comparison: scikit-learn.org" style="width: 100%" loading="lazy"&gt;&lt;/a&gt;
&lt;ul&gt;&lt;li&gt;Confidence interval: &lt;a href="https://online.stat.psu.edu/stat501/node/644" target="_blank"&gt;linear regression coefficient&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;a href="/theme/images/1*hQ5pabjmSByQSC5O4r_uRw.png.png"&gt;&lt;img src="/theme/images/1*hQ5pabjmSByQSC5O4r_uRw.png.png" alt="t-interval for slope parameter beta_1" style="width: 100%" loading="lazy"&gt;&lt;/a&gt;
&lt;ul&gt;&lt;li&gt;&lt;a href="https://a16z.com/2020/10/15/the-emerging-architectures-for-modern-data-infrastructure/" target="_blank"&gt;Data and ML Infrastructure (a16z)&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;a href="/theme/images/1*LYBSxf0MPcERPzkEJlk9Cw.png.png"&gt;&lt;img src="/theme/images/1*LYBSxf0MPcERPzkEJlk9Cw.png.png" alt="A Unified Data Infra" style="width: 100%" loading="lazy"&gt;&lt;/a&gt;
&lt;a href="/theme/images/1*MqMX4k5IupAK9T9vKs5h8g.png.png"&gt;&lt;img src="/theme/images/1*MqMX4k5IupAK9T9vKs5h8g.png.png" alt="AI and ML Blueprint" style="width: 100%" loading="lazy"&gt;&lt;/a&gt;
&lt;ul&gt;&lt;li&gt;&lt;a href="https://scikit-learn.org/stable/modules/mixture.html#estimation-algorithm-expectation-maximization" target="_blank"&gt;Expectation-maximization (EM)&lt;/a&gt;: assumes random components and computes for each point a probability of being generated by each component of the model. Then iteratively tweaks the parameters to maximize the likelihood of the data given those assignments. Example: &lt;a href="https://scikit-learn.org/stable/modules/mixture.html#gaussian-mixture" target="_blank"&gt;Gaussian Mixture&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;ul&gt;&lt;li&gt;&lt;a href="https://online.stat.psu.edu/stat501/lesson/6/6.2#paragraph--785" target="_blank"&gt;F-statistic&lt;/a&gt;: determines whether to reject a full model (F) in favor of a reduced (R) model. Reject full model if F is large — or equivalently if its associated p-value is small&lt;/li&gt;&lt;/ul&gt;
&lt;a href="/theme/images/1*7Vz6m3tqtLAvxF_Xqe2JAQ.png.png"&gt;&lt;img src="/theme/images/1*7Vz6m3tqtLAvxF_Xqe2JAQ.png.png" alt="F* statistic equation" style="width: 100%" loading="lazy"&gt;&lt;/a&gt;
&lt;ul&gt;&lt;li&gt;&lt;a href="https://scikit-learn.org/stable/modules/ensemble.html#gradient-boosting" target="_blank"&gt;Gradient Boosting&lt;/a&gt;: optimization of arbitrary differentiable loss functions. — Risk of overfitting&lt;/li&gt;&lt;/ul&gt;
&lt;ul&gt;&lt;li&gt;&lt;a href="https://scikit-learn.org/stable/modules/neighbors.html#nearest-neighbors-classification" target="_blank"&gt;KNN&lt;/a&gt;: + Simple, flexible, naturally handles multiple classes. — Slow at scale, sensitive to feature scaling and irrelevant features&lt;/li&gt;&lt;/ul&gt;
&lt;ul&gt;&lt;li&gt;&lt;a href="https://scikit-learn.org/stable/modules/clustering.html#k-means" target="_blank"&gt;K-means&lt;/a&gt;: aims to choose centroids that minimize the inertia, or within-cluster sum-of-squares criterion. Use the &lt;a href="https://www.scikit-yb.org/en/latest/api/cluster/elbow.html" target="_blank"&gt;“elbow” method&lt;/a&gt; to identify the right number of means&lt;/li&gt;&lt;/ul&gt;
&lt;ul&gt;&lt;li&gt;&lt;a href="https://scikit-learn.org/stable/modules/linear_model.html#lasso" target="_blank"&gt;Lasso&lt;/a&gt;: linear model regularization technique with tendency to prefer solutions with fewer non-zero coefficients&lt;/li&gt;&lt;/ul&gt;
&lt;a href="/theme/images/1*bvk1Esh-TGPCIub2ggNzQg.png.png"&gt;&lt;img src="/theme/images/1*bvk1Esh-TGPCIub2ggNzQg.png.png" alt="Lasso equation" style="width: 100%" loading="lazy"&gt;&lt;/a&gt;
&lt;ul&gt;&lt;li&gt;&lt;a href="https://scikit-learn.org/stable/auto_examples/model_selection/plot_learning_curve.html#plotting-learning-curves" target="_blank"&gt;Learning Curve&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;a href="/theme/images/1*fz1sqw361u7Y_D1G-aDEmw.png.png"&gt;&lt;img src="/theme/images/1*fz1sqw361u7Y_D1G-aDEmw.png.png" alt="Learning Curve example" style="width: 100%" loading="lazy"&gt;&lt;/a&gt;
&lt;ul&gt;&lt;li&gt;&lt;a href="https://sklearn.org/modules/lda_qda.html#mathematical-formulation-of-the-lda-and-qda-classifiers" target="_blank"&gt;Linear Discriminant Analysis (LDA)&lt;/a&gt;: A classifier with a linear decision boundary, generated by fitting class conditional densities to the data and using Bayes’ rule. The model fits a Gaussian density to each class, assuming that all classes share the same covariance matrix.&lt;/li&gt;&lt;/ul&gt;
&lt;ul&gt;&lt;li&gt;Linear regression&lt;a href="https://online.stat.psu.edu/stat500/lesson/9/9.2/9.2.3#paragraph--3265" target="_blank"&gt; assumptions&lt;/a&gt; (LINE): 1) Linearity, 2) Independence of errors, 3) Normality of errors, 4) Equal variances. Tests of assumptions: i) plot each feature on x-axis vs y_error, ii) plot y_predicted on x-axis vs y_error, iii) histogram of errors&lt;/li&gt;&lt;/ul&gt;
&lt;ul&gt;&lt;li&gt;&lt;a href="https://rmartinshort.jimdofree.com/2019/02/17/overfitting-bias-variance-and-leaning-curves/" target="_blank"&gt;Overfitting, bias-variance and learning curves&lt;/a&gt;. Overfitting (high variance) options: more data, increase regularization, or decrease model complexity&lt;/li&gt;&lt;/ul&gt;
&lt;ul&gt;&lt;li&gt;&lt;a href="https://online.stat.psu.edu/stat462/node/195/" target="_blank"&gt;Overspecified&lt;/a&gt; model: can be used for prediction of the label, but should not be used to ascribe the effect of a feature on the label&lt;/li&gt;&lt;/ul&gt;
&lt;ul&gt;&lt;li&gt;&lt;a href="https://scikit-learn.org/stable/modules/decomposition.html#pca" target="_blank"&gt;PCA&lt;/a&gt;: transform data using k vectors that minimize the perpendicular distance to points. PCA can be also thought of as an &lt;a href="https://online.stat.psu.edu/stat505/lesson/11/11.2" target="_blank"&gt;eigenvalue/engenvector decomposition&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;ul&gt;&lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Pearson_correlation_coefficient" target="_blank"&gt;Pearson’s correlation coefficient&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;a href="/theme/images/1*qtdPV-XQhTYACKS7beLDpg.jpeg.png"&gt;&lt;img src="/theme/images/1*qtdPV-XQhTYACKS7beLDpg.jpeg.png" alt="Correlation formula" style="width: 100%" loading="lazy"&gt;&lt;/a&gt;
&lt;ul&gt;&lt;li&gt;&lt;a href="https://scikit-learn.org/stable/modules/model_evaluation.html#receiver-operating-characteristic-roc" target="_blank"&gt;Receiver operating characteristic (ROC)&lt;/a&gt;: relates true positive rate (y-axis) and false positive rate (x-axis). A &lt;a href="https://en.wikipedia.org/wiki/Precision_and_recall#Recall" target="_blank"&gt;confusion&lt;/a&gt; matrix defines TPR = TP / (TP + FN) and FPR = FP / (FP + TN)&lt;/li&gt;&lt;/ul&gt;
&lt;ul&gt;&lt;li&gt;&lt;a href="https://scikit-learn.org/stable/modules/naive_bayes.html#naive-bayes" target="_blank"&gt;Naive Bayes&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;ul&gt;&lt;li&gt;&lt;a href="http://cecas.clemson.edu/~ahoover/ece854/lecture-notes/lecture-normeqs.pdf" target="_blank"&gt;Normal Equation&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;a href="/theme/images/1*i0ylsCBDeVY5rFlGa9AYWg.png.png"&gt;&lt;img src="/theme/images/1*i0ylsCBDeVY5rFlGa9AYWg.png.png" alt="Normal equation" style="width: 100%" loading="lazy"&gt;&lt;/a&gt;
&lt;ul&gt;&lt;li&gt;&lt;a href="https://scikit-learn.org/stable/modules/ensemble.html#random-forests" target="_blank"&gt;Random Forests&lt;/a&gt;: each tree is built using a sample of rows (with replacement) from training set. + Less prone to overfitting&lt;/li&gt;&lt;/ul&gt;
&lt;ul&gt;&lt;li&gt;&lt;a href="https://scikit-learn.org/stable/modules/linear_model.html#ridge-regression-and-classification" target="_blank"&gt;Ridge Regression&lt;/a&gt; regularization: imposes a penalty on the size of the coefficients&lt;/li&gt;&lt;/ul&gt;
&lt;a href="/theme/images/1*fekJIBmDHMoU2zQ6wVmQkA.png.png"&gt;&lt;img src="/theme/images/1*fekJIBmDHMoU2zQ6wVmQkA.png.png" alt="Ridge Regression" style="width: 100%" loading="lazy"&gt;&lt;/a&gt;
&lt;ul&gt;&lt;li&gt;&lt;a href="https://scikit-learn.org/stable/modules/model_evaluation.html#r2-score" target="_blank"&gt;R2&lt;/a&gt;: strength of a linear relationship. Could be 0 for nonlinear relationships. Never worsens with more features&lt;/li&gt;&lt;/ul&gt;
&lt;ul&gt;&lt;li&gt;&lt;a href="https://online.stat.psu.edu/stat500/lesson/1/1.5/1.5.3#paragraph--3051" target="_blank"&gt;Sample variance&lt;/a&gt;: divided by n-1 to achieve an unbiased estimator because 1 degree of freedom is used to estimate b0&lt;/li&gt;&lt;/ul&gt;
&lt;ul&gt;&lt;li&gt;&lt;a href="https://www.kaggle.com/residentmario/oversampling-with-smote-and-adasyn" target="_blank"&gt;SMOTE&lt;/a&gt; algorithm is parameterized with k_neighbors. Generate and place a new point on the vector between a minority class point and one of its nearest neighbors, located [0, 1] percent of the way from the original point&lt;/li&gt;&lt;/ul&gt;
&lt;ul&gt;&lt;li&gt;SQL &lt;a href="https://docs.microsoft.com/en-us/sql/t-sql/language-elements/coalesce-transact-sql?view=sql-server-ver15" target="_blank"&gt;COALESCE()&lt;/a&gt;: evaluates the arguments in order and returns the current value of the first expression that initially doesn’t evaluate to NULL&lt;/li&gt;&lt;/ul&gt;
&lt;ul&gt;&lt;li&gt;SQL window function: &lt;a href="https://docs.microsoft.com/en-us/sql/t-sql/functions/row-number-transact-sql?view=sql-server-ver15#d-using-row_number-with-partition" target="_blank"&gt;row_number() and partition()&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;ul&gt;&lt;li&gt;&lt;a href="https://scikit-learn.org/stable/modules/svm.html#svm-classification" target="_blank"&gt;SVM&lt;/a&gt;: Effective in high dimensional spaces (or when number of dimensions &amp;gt; number of examples). SVMs do not directly provide probability estimates&lt;/li&gt;&lt;/ul&gt;
&lt;ul&gt;&lt;li&gt;Stochastic gradient descent cost function&lt;/li&gt;&lt;/ul&gt;
&lt;a href="/theme/images/1*_6C1R-IamnPtIo0jLOoblw.png.png"&gt;&lt;img src="/theme/images/1*_6C1R-IamnPtIo0jLOoblw.png.png" alt="Stochastic gradient descent cost function" style="width: 100%" loading="lazy"&gt;&lt;/a&gt;
&lt;ul&gt;&lt;li&gt;&lt;a href="https://online.stat.psu.edu/stat555/node/36/" target="_blank"&gt;T-test&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;a href="/theme/images/1*R1ysZ-ofSr5wXwE0_emXiQ.png.png"&gt;&lt;img src="/theme/images/1*R1ysZ-ofSr5wXwE0_emXiQ.png.png" alt="T-test formula" style="width: 100%" loading="lazy"&gt;&lt;/a&gt;
&lt;ul&gt;&lt;li&gt;&lt;a href="https://scikit-learn.org/stable/auto_examples/model_selection/plot_validation_curve.html#plotting-validation-curves" target="_blank"&gt;Validation curve&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;a href="/theme/images/1*HVM4sFhGDTNE40xr5aVCiQ.png.png"&gt;&lt;img src="/theme/images/1*HVM4sFhGDTNE40xr5aVCiQ.png.png" alt="validation curve example" style="width: 100%" loading="lazy"&gt;&lt;/a&gt;&lt;/p&gt;</content><category term="Machine Learning"></category></entry><entry><title>Google Colab and AutoML: Auto-sklearn Setup</title><link href="https://adamnovotny.com/blog/google-colab-and-automl-auto-sklearn-setup.html" rel="alternate"></link><published>2020-12-04T00:00:00-05:00</published><updated>2020-12-04T00:00:00-05:00</updated><author><name>Adam Novotny</name></author><id>tag:adamnovotny.com,2020-12-04:/blog/google-colab-and-automl-auto-sklearn-setup.html</id><summary type="html">&lt;p&gt;Auto ML is fast becoming a popular solution to build minimal viable models for new projects. A popular library for Python is &lt;a href="https://automl.github.io/auto-sklearn/master/#" target="_blank"&gt;Auto-sklearn&lt;/a&gt; that leverages the most popular Python ML library &lt;a href="http://sklearn.org" target="_blank"&gt;scikit-learn&lt;/a&gt;. Auto-sklearn runs a smart search over scikit-learn models and parameters to find the best performing ensemble of models …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Auto ML is fast becoming a popular solution to build minimal viable models for new projects. A popular library for Python is &lt;a href="https://automl.github.io/auto-sklearn/master/#" target="_blank"&gt;Auto-sklearn&lt;/a&gt; that leverages the most popular Python ML library &lt;a href="http://sklearn.org" target="_blank"&gt;scikit-learn&lt;/a&gt;. Auto-sklearn runs a smart search over scikit-learn models and parameters to find the best performing ensemble of models.&lt;/p&gt;

&lt;p&gt;&lt;a href="/theme/images/1*n6-MAHisW5-xLrEUndHe5g.png.png"&gt;&lt;img src="/theme/images/1*n6-MAHisW5-xLrEUndHe5g.png.png" alt="Logos of Google Drive + Colab + Scikit-learn + Auto-sklearn" style="width: 100%" loading="lazy"&gt;&lt;/a&gt;
&lt;p&gt;This tutorial describes how to setup Auto-sklearn on &lt;a href="https://colab.research.google.com/" target="_blank"&gt;Google Colab&lt;/a&gt;. The complete &lt;a href="https://gist.github.com/adamnovotnycom/1df7ef10649d8241c389c96becb7fe37" target="_blank"&gt;notebook gist&lt;/a&gt; includes a toy project that uses an &lt;a href="https://www.kaggle.com/dgomonov/new-york-city-airbnb-open-data" target="_blank"&gt;old Airbnb dataset&lt;/a&gt; from Kaggle.&lt;/p&gt;
&lt;p&gt;The key first step is to install linux dependencies alongside Auto-sklearn:&lt;/p&gt;
&lt;pre&gt;!sudo apt-get install build-essential swig
!pip install auto-sklearn==0.11.1&lt;/pre&gt;
&lt;p&gt;After running these commands in Colab, restart the Colab runtime and run all commands again.&lt;/p&gt;
&lt;p&gt;The Airbnb dataset can be used for a regression project where price is the label. I selected a few numerical and categorical features randomly so the dataset used for modeling has the following characteristics:&lt;/p&gt;
&lt;a href="/theme/images/1*-lXTkg7Y9W-XMdNPR5KPkA.png.png"&gt;&lt;img src="/theme/images/1*-lXTkg7Y9W-XMdNPR5KPkA.png.png" alt="Airbnb dataset description" style="width: 100%" loading="lazy"&gt;&lt;/a&gt;
&lt;p&gt;A more sophisticated ML project would require a detailed feature selection process and data analysis at this stage. For example, does the maximum value of 1,250 for minimum_nights make sense? In this case, I am simply showing the Auto-sklearn setup so I will skip these time consuming steps.&lt;/p&gt;
&lt;p&gt;Next, all numerical features are &lt;a href="https://en.wikipedia.org/wiki/Standard_score" target="_blank"&gt;standardized&lt;/a&gt; and missing values filled. Scikit-learn (and therefore Auto-sklearn) cannot handle string categories so categorical features are &lt;a href="https://machinelearningmastery.com/why-one-hot-encode-data-in-machine-learning/" target="_blank"&gt;one hot encoded&lt;/a&gt;. Also, infrequently appearing categories are combined into a single bucket to combat the &lt;a href="https://en.wikipedia.org/wiki/Curse_of_dimensionality" target="_blank"&gt;Curse of dimensionality&lt;/a&gt;. In this case, any neighborhood that appears less than 0.5% of the time is renamed to “neighborhood_other”. Before transformations, the first 5 rows of the training dataset have the following items:&lt;/p&gt;
&lt;a href="/theme/images/1*5zbUTS8k6rTqTYUtpATzlw.png.png"&gt;&lt;img src="/theme/images/1*5zbUTS8k6rTqTYUtpATzlw.png.png" alt="Training dataset before transformations" style="width: 100%" loading="lazy"&gt;&lt;/a&gt;
&lt;p&gt;After transformations, the first few columns of the 5 rows look like this:&lt;/p&gt;
&lt;a href="/theme/images/1*AySz4rydwvMNfOnt4v-UpA.png.png"&gt;&lt;img src="/theme/images/1*AySz4rydwvMNfOnt4v-UpA.png.png" alt="Training dataset after transformations" style="width: 100%" loading="lazy"&gt;&lt;/a&gt;
&lt;p&gt;I am finally ready to explore Auto-sklearn using few simple commands that fit a new model:&lt;/p&gt;
&lt;pre&gt;import autosklearn.regression
automl = autosklearn.regression.AutoSklearnRegressor(
  time_left_for_this_task=120,
  per_run_time_limit=30,
  n_jobs=1
)
automl.fit(
  X_train_transformed,
  y_train
)&lt;/pre&gt;
&lt;p&gt;Finally, here is how the model performs on a test dataset:&lt;/p&gt;
&lt;pre&gt;import sklearn.metrics
predictions = automl.predict(X_test_transformed)
sklearn.metrics.r2_score(y_test, predictions)
 output: 0.1862&lt;/pre&gt;
&lt;p&gt;An alternative approach that doesn’t use Auto-sklearn would be to manually select a model and run a grid search to find best parameters. A typical, well-performing algorithm is RandomForestRegressor so I might try the following:&lt;/p&gt;
&lt;pre&gt;from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import GridSearchCV
model = RandomForestRegressor(max_depth=3, random_state=0)
parameters = {
  "max_depth": (2, 3, 5)
}
grid = GridSearchCV(model, parameters, cv=5, scoring="r2")
grid.fit(X_train_transformed, y_train.values.ravel())&lt;/pre&gt;
&lt;p&gt;For comparison, the performance of this model would be:&lt;/p&gt;
&lt;pre&gt;predictions = grid.predict(X_test_transformed)
sklearn.metrics.r2_score(y_test, predictions)
 output: 0.0982&lt;/pre&gt;
&lt;p&gt;Impressively, the default Auto-sklearn &lt;a href="https://en.wikipedia.org/wiki/Coefficient_of_determination" target="_blank"&gt;R2&lt;/a&gt; performance of 0.186 is nearly twice as good as simplistic scikit-learn-only performance of 0.098. These are not intended to be absolute benchmarks because I performed no customization but the relative performance is worth noting. The results suggest that Auto-sklearn can set a very reasonable lower performance bound that no model deployed in production should underperform.&lt;/p&gt;
&lt;p&gt;More about me: &lt;a href="https://adamnovotny.com" target="_blank"&gt;adamnovotny.com&lt;/a&gt;&lt;/p&gt;&lt;/p&gt;</content><category term="Machine Learning"></category></entry><entry><title>Custom scikit-learn Pipeline</title><link href="https://adamnovotny.com/blog/custom-scikit-learn-pipeline.html" rel="alternate"></link><published>2020-06-25T00:00:00-05:00</published><updated>2020-06-25T00:00:00-05:00</updated><author><name>Adam Novotny</name></author><id>tag:adamnovotny.com,2020-06-25:/blog/custom-scikit-learn-pipeline.html</id><summary type="html">&lt;p&gt;I have gone through many iterations of what my preferred scikit-learn custom pipeline looks like. As of 6/2020, here is my latest iteration.&lt;/p&gt;

&lt;p&gt;&lt;a href="/theme/images/1*8PUAA9DjMv6CMsPWhbayIQ.png.png"&gt;&lt;img src="/theme/images/1*8PUAA9DjMv6CMsPWhbayIQ.png.png" alt="scikit-learn logo" style="width: 100%" loading="lazy"&gt;&lt;/a&gt;
&lt;p&gt;In general, a machine learning pipeline should have the following characteristics:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Include every step shared between training and scoring to ensure consistency. The pipeline does not …&lt;/li&gt;&lt;/ul&gt;&lt;/p&gt;</summary><content type="html">&lt;p&gt;I have gone through many iterations of what my preferred scikit-learn custom pipeline looks like. As of 6/2020, here is my latest iteration.&lt;/p&gt;

&lt;p&gt;&lt;a href="/theme/images/1*8PUAA9DjMv6CMsPWhbayIQ.png.png"&gt;&lt;img src="/theme/images/1*8PUAA9DjMv6CMsPWhbayIQ.png.png" alt="scikit-learn logo" style="width: 100%" loading="lazy"&gt;&lt;/a&gt;
&lt;p&gt;In general, a machine learning pipeline should have the following characteristics:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Include every step shared between training and scoring to ensure consistency. The pipeline does not need to include one-off steps such as removing duplicates which would not be relevant at scoring time.&lt;/li&gt;&lt;/ul&gt;
&lt;ul&gt;&lt;li&gt;Have as few custom components as necessary. For example, when filling missing values in numerical columns with median value, there is no reason NOT to use SimpleImputer class from &lt;a href="https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html" target="_blank"&gt;sklearn.impute&lt;/a&gt;. In my example gist below I included a custom FeatureSelector class just to illustrate how to defined a custom pipeline step. In reality, an already defined scikit-learn class with the same functionality would be used.&lt;/li&gt;&lt;/ul&gt;
&lt;ul&gt;&lt;li&gt;Allow for parallel preprocessing subject to the computing environment limits. For example, the preprocessing of categorical and numerical features can take place in parallel because the transformation steps do not affect each other.&lt;/li&gt;&lt;/ul&gt;
&lt;ul&gt;&lt;li&gt;(optional) The pipeline should be as small as possible when serialized to enable a serverless deployment. Serverless frameworks such as &lt;a href="https://docs.aws.amazon.com/lambda/latest/dg/gettingstarted-limits.html" target="_blank"&gt;AWS Lambda limit&lt;/a&gt; the zipped deployment size of all code. As of 6/2020 Lambda limits the deployment size to 250MB. This is enough for certain combinations of code such as scikit-learn and XGBoost with certain optimization.&lt;/li&gt;&lt;/ul&gt;
&lt;p&gt;&lt;a href="https://gist.github.com/adamnovotnycom/dda3bad52112f64d1ef2d136eeb66b4e" target="_blank"&gt;Full pipeline Gist&lt;/a&gt;&lt;/p&gt;
&lt;a href="/theme/images/1*1G7mCD8y1N2C0rGM0aESDg.png.png"&gt;&lt;img src="/theme/images/1*1G7mCD8y1N2C0rGM0aESDg.png.png" alt="Pipeline imports and helper functions. Gist: https://gist.github.com/excitedAtom/dda3bad52112f64d1ef2d136eeb66b4e" style="width: 100%" loading="lazy"&gt;&lt;/a&gt;
&lt;a href="/theme/images/1*AKzavQV0uZzuk4dn34mOhw.png.png"&gt;&lt;img src="/theme/images/1*AKzavQV0uZzuk4dn34mOhw.png.png" alt="Pipeline definition. Gist: https://gist.github.com/excitedAtom/dda3bad52112f64d1ef2d136eeb66b4e" style="width: 100%" loading="lazy"&gt;&lt;/a&gt;
&lt;a href="/theme/images/1*oSp6ZOgKerYwc54t14A9ng.png.png"&gt;&lt;img src="/theme/images/1*oSp6ZOgKerYwc54t14A9ng.png.png" alt="Pipeline fit — sample data. Gist: https://gist.github.com/excitedAtom/dda3bad52112f64d1ef2d136eeb66b4e" style="width: 100%" loading="lazy"&gt;&lt;/a&gt;
&lt;h4&gt;Description&lt;/h4&gt;
&lt;ul&gt;&lt;li&gt;FeatureSelector is defined to illustrate what a custom pipeline step looks like. In this case, the step simply selects a subset of columns to which the transformation defined in the next step of a scikit-learn Pipeline class is applied.&lt;/li&gt;&lt;/ul&gt;
&lt;ul&gt;&lt;li&gt;Numerical features are transformed using a scikit-learn Pipeline class. First, the appropriate columns are selected using the above FeatureSelector class. Then all numerical columns have their missing values filled using each column’s median value. Lastly, all numerical columns are scaled.&lt;/li&gt;&lt;/ul&gt;
&lt;ul&gt;&lt;li&gt;Categorical columns are similarly transformed. OneHotEncoder is applied transforming columns containing categorical values. Importantly, I like to define the categories argument to prevent the &lt;a href="https://en.wikipedia.org/wiki/Curse_of_dimensionality" target="_blank"&gt;Curse of dimensionality&lt;/a&gt; that might occur when too many categories are present.&lt;/li&gt;&lt;/ul&gt;&lt;/p&gt;</content><category term="Machine Learning"></category></entry><entry><title>Machine Learning Tutorial #4: Deployment</title><link href="https://adamnovotny.com/blog/machine-learning-tutorial-4-deployment.html" rel="alternate"></link><published>2018-09-02T00:00:00-05:00</published><updated>2018-09-02T00:00:00-05:00</updated><author><name>Adam Novotny</name></author><id>tag:adamnovotny.com,2018-09-02:/blog/machine-learning-tutorial-4-deployment.html</id><summary type="html">&lt;h4&gt;Topics: Stack Selection, Heroku, Testing&lt;/h4&gt;

&lt;p&gt;&lt;a href="/theme/images/1*T_-rIQ8yUgPba_ezxt6ogg.png.png"&gt;&lt;img src="/theme/images/1*T_-rIQ8yUgPba_ezxt6ogg.png.png" alt="Machine Learning project overview. Author: Adam Novotny" style="width: 100%" loading="lazy"&gt;&lt;/a&gt;
&lt;p&gt;In this final phase of the series, I will suggest a few options ML engineers have to deploy their code. In large organizations, this part of the project will be handled by a specialized team which is especially important when scaling is a concern. Other …&lt;/p&gt;&lt;/p&gt;</summary><content type="html">&lt;h4&gt;Topics: Stack Selection, Heroku, Testing&lt;/h4&gt;

&lt;p&gt;&lt;a href="/theme/images/1*T_-rIQ8yUgPba_ezxt6ogg.png.png"&gt;&lt;img src="/theme/images/1*T_-rIQ8yUgPba_ezxt6ogg.png.png" alt="Machine Learning project overview. Author: Adam Novotny" style="width: 100%" loading="lazy"&gt;&lt;/a&gt;
&lt;p&gt;In this final phase of the series, I will suggest a few options ML engineers have to deploy their code. In large organizations, this part of the project will be handled by a specialized team which is especially important when scaling is a concern. Other tutorials in this series: &lt;a href="https://medium.com/coinmonks/machine-learning-tutorial-1-preprocessing-d90198e37577" target="_blank"&gt;#1 Preprocessing&lt;/a&gt;, &lt;a href="https://medium.com/coinmonks/machine-learning-tutorial-2-training-f6f735830838" target="_blank"&gt;#2 Training&lt;/a&gt;, &lt;a href="https://medium.com/coinmonks/machine-learning-tutorial-3-evaluation-a157f90914c9" target="_blank"&gt;#3 Evaluation&lt;/a&gt; , #4 Deployment (this article). &lt;a href="https://github.com/adam5ny/blogs/tree/master/ml-deployment" target="_blank"&gt;Github code&lt;/a&gt;.&lt;/p&gt;
&lt;h4&gt;Stack Selection&lt;/h4&gt;
&lt;p&gt;The number of options to deploy ML code is numerous but I typically decide between at least the three general buckets:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Solution provided as-a-service (e.g. Microsoft Azure Machine Learning Studio)&lt;/li&gt;&lt;/ul&gt;
&lt;ul&gt;&lt;li&gt;Serverless function (e.g. &lt;a href="https://docs.aws.amazon.com/lambda/latest/dg/python-programming-model.html" target="_blank"&gt;AWS Lambda&lt;/a&gt;)&lt;/li&gt;&lt;/ul&gt;
&lt;ul&gt;&lt;li&gt;Custom backend code (e.g. &lt;a href="http://flask.pocoo.org/docs/0.12/" target="_blank"&gt;Python Flask&lt;/a&gt; served by &lt;a href="https://devcenter.heroku.com/articles/getting-started-with-python" target="_blank"&gt;Heroku&lt;/a&gt;)&lt;/li&gt;&lt;/ul&gt;
&lt;h4&gt;As-a-service solution&lt;/h4&gt;
&lt;p&gt;Platforms such as Microsoft Azure Machine Learning Studio offer the full suite of tools for the entire project including preprocessing and training. Custom API endpoints are usually easy to generate and writing code is often not necessary thanks to drag-and-drop interfaces. The solutions are often well optimized for &lt;a href="https://en.wikipedia.org/wiki/Lazy_learning" target="_blank"&gt;lazy learners&lt;/a&gt; where evaluation is the most expensive computational step. The downside is that it is sometimes more challenging to bring in custom code (such as the final model) without going through all the project steps on the platform.&lt;/p&gt;
&lt;a href="/theme/images/1*4F3z9NovnqtOtIRWRCJn_Q.jpeg.png"&gt;&lt;img src="/theme/images/1*4F3z9NovnqtOtIRWRCJn_Q.jpeg.png" alt="As-a-service deployment example: Microsoft Azure" style="width: 100%" loading="lazy"&gt;&lt;/a&gt;
&lt;h4&gt;Serverless function&lt;/h4&gt;
&lt;p&gt;Serverless functions are a good solution for inexpensive computations. AWS uses default timeout of 3 seconds for a function to complete. While timeouts can be extended, the default value is often a good general guideline when deciding about suitability. Lambda only allows 50MB of custom code to be uploaded which is generally not enough for most machine learning purposes. However, functions are well suited for fast computations such as linear regression models. Another downside is that platforms support only specific languages. In terms of Python solutions, AWS Lambda supports versions 2.7 and 3.6 only at the time of writing this article.&lt;/p&gt;
&lt;h4&gt;Custom backend code&lt;/h4&gt;
&lt;p&gt;Writing a custom backend code on platform such as Heroku or Amazon’s EC2 allows us to replicate fully the code we write on local machines. The code and server deployment can be fully customized for the type of ML algorithm we are deploying. The downside of such solutions is their operational complexity because we need to focus on many steps unrelated to ML such as security.&lt;/p&gt;
&lt;p&gt;I will deploy the code on &lt;a href="https://devcenter.heroku.com/articles/getting-started-with-python" target="_blank"&gt;Heroku&lt;/a&gt; which offers a free tier for testing purposes. The lightweight &lt;a href="http://flask.pocoo.org/" target="_blank"&gt;Flask framework&lt;/a&gt; will drive the backend. The primary reason for this choice is that it allows us to reuse essentially all the code written in previous tutorials for the backend. We can install Flask with Python 3.6 and all machine learning libraries we use previously side by side.&lt;/p&gt;
&lt;p&gt;The entire backend code to run the app is literally a few lines long with Flask:&lt;/p&gt;
&lt;pre&gt;import pickle
import pandas as pd
from flask import Flask, jsonify, request, make_response&lt;/pre&gt;
&lt;pre&gt;app = Flask(&lt;strong&gt;name&lt;/strong&gt;)&lt;/pre&gt;
&lt;pre&gt;&lt;a href="http://twitter.com/app" target="_blank"&gt;@app&lt;/a&gt;.route('/forecast', methods=["POST"])
def forecast_post():
    """
    Args:
        request.data: json pandas dataframe
            example: {
                "columns": ["date", "open", "high", "low", "close",
                   "volume"],
                "index":[1, 0],
                "data": [
                   [1532390400000, 108, 108, 107, 107, 26316],
                   [1532476800000, 107, 111, 107, 110, 30702]]
            }
    """
    if request.data:
        df = pd.read_json(request.data, orient='split')
        X = preprocess(df)
        model = pickle.load(open("dtree_model.pkl", "rb"))
        y_pred = run_model(X, model)
        resp = make_response(jsonify({
           "y_pred": json.dumps(y_pred.tolist())
        }), 200)
        return resp
    else:
        return make_response(jsonify({"message": "no data"}), 400)&lt;/pre&gt;
&lt;ul&gt;&lt;li&gt;pd.read_json(…): reads data from &lt;a href="https://en.wikipedia.org/wiki/POST_(HTTP)" target="_blank"&gt;POST request&lt;/a&gt; which is a json object corresponding to price data formatted the same way as Yahoo finance prices (our original data source)&lt;/li&gt;&lt;/ul&gt;
&lt;ul&gt;&lt;li&gt;preprocess(…): copy of our code from the &lt;a href="https://medium.com/coinmonks/machine-learning-tutorial-1-preprocessing-d90198e37577" target="_blank"&gt;Preprocessing&lt;/a&gt; tutorial that manipulates raw price data into features. Importantly, the scaler used must be the exact same we used in Preprocessing so it has to be saved to pickle file first during Preprocessing and loaded from pickle now&lt;/li&gt;&lt;/ul&gt;
&lt;ul&gt;&lt;li&gt;run_model(…): loads and runs our saved final model from the &lt;a href="https://medium.com/coinmonks/machine-learning-tutorial-2-training-f6f735830838" target="_blank"&gt;Training&lt;/a&gt; tutorial&lt;/li&gt;&lt;/ul&gt;
&lt;ul&gt;&lt;li&gt;make_response(…): returns forecasts&lt;/li&gt;&lt;/ul&gt;
&lt;h4&gt;Heroku&lt;/h4&gt;
&lt;p&gt;Deploying our prediction code to Heroku will require that we collect at least two necessary pieces of our code from previous tutorials: the final model (saved as a pickle file) and the code from the &lt;a href="https://medium.com/coinmonks/machine-learning-tutorial-1-preprocessing-d90198e37577" target="_blank"&gt;Preprocessing&lt;/a&gt; tutorial that transforms the original features we collected from the real world to features our model can handle.&lt;/p&gt;
&lt;p&gt;I will not go into details about how to deploy a Docker app on Heroku. There are plenty of good materials including Heroku’s documentation, which is excellent. All the necessary code to run and deploy the Docker app on Heroku is also in the &lt;a href="https://github.com/adam5ny/blogs/tree/master/ml-deployment" target="_blank"&gt;Github &lt;/a&gt;repo. There are a few key steps to remember:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Save Dockerfile as Dockerfile.web which is a container of all code necessary to run the app&lt;/li&gt;&lt;/ul&gt;
&lt;ul&gt;&lt;li&gt;Deploy container using command &lt;a href="https://devcenter.heroku.com/articles/container-registry-and-runtime" target="_blank"&gt;heroku container:push&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;ul&gt;&lt;li&gt;Release container using command &lt;a href="https://devcenter.heroku.com/articles/container-registry-and-runtime" target="_blank"&gt;heroku container:release&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;p&gt;At this point our code is deployed which we can test using &lt;a href="https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=1&amp;cad=rja&amp;uact=8&amp;ved=2ahUKEwjmut-U1JvdAhVKsqQKHaQUBg0QFjAAegQIBRAC&amp;url=https%3A%2F%2Fwww.getpostman.com%2F&amp;usg=AOvVaw1vWzpwzQOHi5ErKZnywLDR" target="_blank"&gt;Postman&lt;/a&gt; to make a manual forecast request:&lt;/p&gt;
&lt;a href="/theme/images/1*5kvKnVEez88tZ96uTtOqjg.png.png"&gt;&lt;img src="/theme/images/1*5kvKnVEez88tZ96uTtOqjg.png.png" alt="Postman sample request" style="width: 100%" loading="lazy"&gt;&lt;/a&gt;
&lt;p&gt;The date is represented by Unix timestamp. The first Body window consists of inputs we provide to the endpoint in the form of prices. The second window returns forecasts from the app.&lt;/p&gt;
&lt;h4&gt;Testing&lt;/h4&gt;
&lt;p&gt;To test the implementation, I will reuse the code from the Evaluation step. However, instead of making predictions locally using our sklearn model, I will use the Heroku app to predict the 691 samples from Evaluation as a batch. The goal is for our predictions we made on a local machine to perfectly match those made using our deployment stack.&lt;/p&gt;
&lt;p&gt;This step is critical to ensure that we can replicate our results remotely using a pre-trained model. The testing code is also available on &lt;a href="https://github.com/adam5ny/blogs/blob/master/ml-deployment/backend/tests/test_app.py" target="_blank"&gt;Github&lt;/a&gt;. We confirm that the performance of our Heroku app matches the performance generated locally in the Evaluation tutorial:&lt;/p&gt;
&lt;a href="/theme/images/1*Oewaabcu926MZpC-zFFpHQ.png.png"&gt;&lt;img src="/theme/images/1*Oewaabcu926MZpC-zFFpHQ.png.png" alt="Tested deployment performance matches evaluation results" style="width: 100%" loading="lazy"&gt;&lt;/a&gt;
&lt;p&gt;To conclude, the project is intended to provide an overview of the kind of thinking a data science project entails. The code should not be used in production and is provided solely for illustrative purposes. As always, I welcome all constructive feedback (positive or negative) on &lt;a href="https://twitter.com/adam5ny" target="_blank"&gt;Twitter&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Other tutorials in this series: &lt;a href="https://medium.com/coinmonks/machine-learning-tutorial-1-preprocessing-d90198e37577" target="_blank"&gt;#1 Preprocessing&lt;/a&gt;, &lt;a href="https://medium.com/coinmonks/machine-learning-tutorial-2-training-f6f735830838" target="_blank"&gt;#2 Training&lt;/a&gt;, &lt;a href="https://medium.com/coinmonks/machine-learning-tutorial-3-evaluation-a157f90914c9" target="_blank"&gt;#3 Evaluation&lt;/a&gt;, #4 Deployment (this article). &lt;a href="https://github.com/adam5ny/blogs/tree/master/ml-deployment" target="_blank"&gt;Github code&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Author website: &lt;a href="https://www.adamnovotny.com/" target="_blank"&gt;adamnovotny.com&lt;/a&gt;&lt;/p&gt;&lt;/p&gt;</content><category term="Machine Learning"></category></entry><entry><title>Machine Learning Tutorial #3: Evaluation</title><link href="https://adamnovotny.com/blog/machine-learning-tutorial-3-evaluation.html" rel="alternate"></link><published>2018-08-19T00:00:00-05:00</published><updated>2018-08-19T00:00:00-05:00</updated><author><name>Adam Novotny</name></author><id>tag:adamnovotny.com,2018-08-19:/blog/machine-learning-tutorial-3-evaluation.html</id><summary type="html">&lt;h4&gt;Topics: Performance Metrics, Commentary&lt;/h4&gt;

&lt;p&gt;&lt;a href="/theme/images/1*iPgIcpnc-nzkigs6RaTZBw.png.png"&gt;&lt;img src="/theme/images/1*iPgIcpnc-nzkigs6RaTZBw.png.png" alt="Machine Learning project overview. Author: Adam Novotny" style="width: 100%" loading="lazy"&gt;&lt;/a&gt;
&lt;p&gt;In this third phase of the series, I will explore the Evaluation part of the ML project. I will reuse some of the code and solutions from the second Training phase. However, it is important to note that the Evaluation phase should be completely separate from …&lt;/p&gt;&lt;/p&gt;</summary><content type="html">&lt;h4&gt;Topics: Performance Metrics, Commentary&lt;/h4&gt;

&lt;p&gt;&lt;a href="/theme/images/1*iPgIcpnc-nzkigs6RaTZBw.png.png"&gt;&lt;img src="/theme/images/1*iPgIcpnc-nzkigs6RaTZBw.png.png" alt="Machine Learning project overview. Author: Adam Novotny" style="width: 100%" loading="lazy"&gt;&lt;/a&gt;
&lt;p&gt;In this third phase of the series, I will explore the Evaluation part of the ML project. I will reuse some of the code and solutions from the second Training phase. However, it is important to note that the Evaluation phase should be completely separate from training except for using the final model produced in the Training step. Other tutorials in this series: &lt;a href="https://medium.com/coinmonks/machine-learning-tutorial-1-preprocessing-d90198e37577" target="_blank"&gt;#1 Preprocessing&lt;/a&gt;, &lt;a href="https://medium.com/coinmonks/machine-learning-tutorial-2-training-f6f735830838" target="_blank"&gt;#2 Training&lt;/a&gt;, #3 Evaluation (this article), &lt;a href="https://medium.com/@adam5ny/machine-learning-tutorial-4-deployment-79764123e9e1" target="_blank"&gt;#4 Prediction&lt;/a&gt;. &lt;a href="https://github.com/adam5ny/blogs/tree/master/ml-evaluation" target="_blank"&gt;Github code&lt;/a&gt;.&lt;/p&gt;
&lt;h4&gt;Performace Metrics&lt;/h4&gt;
&lt;p&gt;The goal of this section is to determine how our model from the Training step performs on real life data it has not learned from. First, we have to load the model we saved as the Final model:&lt;/p&gt;
&lt;pre&gt;model = pickle.load(open("dtree_model.pkl", "rb"))&lt;/p&gt;
&lt;blockquote&gt;
&lt;blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;model
DecisionTreeRegressor(criterion='mse', max_depth=3, max_features=None, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, min_samples_leaf=1, min_samples_split=5, min_weight_fraction_leaf=0.0, presort=False, random_state=1, splitter='best')&lt;/pre&gt;
&lt;p&gt;Next, we will load the testing data we created in the Preprocessing part of this tutorial. The primary reason why I keep the Evaluation section separate from Training is precisely this step. I keep the code separate as well to ensure that no information from training leaks into evaluation. To restate, we should have not seen the data used in this section at any point until now.&lt;/p&gt;
&lt;pre&gt;X = pd.read_csv("X_test.csv", header=0)
y = pd.read_csv("y_test.csv", header=0)&lt;/pre&gt;
&lt;p&gt;At this stage, we may perform additional performance evaluation on top of the Training step. However, I will stick to the metrics used previously: MAE, MSE, R2.&lt;/p&gt;
&lt;a href="/theme/images/1*5Cjov6KncJ3qLJ-fHi6MTg.png.png"&gt;&lt;img src="/theme/images/1*5Cjov6KncJ3qLJ-fHi6MTg.png.png" alt="Decision tree MAE, MSE, R2" style="width: 100%" loading="lazy"&gt;&lt;/a&gt;
&lt;h4&gt;Commentary&lt;/h4&gt;
&lt;p&gt;We have known that our model does not perform well enough in practice from the previous tutorial already. However, as I mentioned before, I went ahead and used it for illustrative purposes here in order to complete the tutorial and to explain the kind of thinking involved in real life projects where performance is not always ideal out of the box as many toy datasets would make one think.&lt;/p&gt;
&lt;p&gt;The key comparison is how well does our model evaluate relative to the training phase. In the case of models ready for production, I would expect the performance in the Evaluation step to be comparable to those of testing folds in the Training phase.&lt;/p&gt;
&lt;p&gt;Comparing the last training test fold &lt;a href="https://medium.com/coinmonks/machine-learning-tutorial-2-training-f6f735830838" target="_blank"&gt;here&lt;/a&gt; (5249 datapoints used to train) and the Evaluation results above:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;MAE: final Training phase ~10^-2. Evaluation phase ~10^-2&lt;/li&gt;&lt;/ul&gt;
&lt;ul&gt;&lt;li&gt;MSE: final Training phase ~10^-4. Evaluation phase ~10^-3&lt;/li&gt;&lt;/ul&gt;
&lt;ul&gt;&lt;li&gt;R²: final Training phase ~0. Evaluation phase ~0&lt;/li&gt;&lt;/ul&gt;
&lt;p&gt;The performance on dataset the model has never seen before is reasonably similar. Nonetheless, overfitting is still something to potentially address. If we had a model ready for production from the Training phase, we would be reasonably confident at this stage that it would perform as we expect on out of sample data.&lt;/p&gt;
&lt;p&gt;Other tutorials in this series: &lt;a href="https://medium.com/coinmonks/machine-learning-tutorial-1-preprocessing-d90198e37577" target="_blank"&gt;#1 Preprocessing&lt;/a&gt;, &lt;a href="https://medium.com/coinmonks/machine-learning-tutorial-2-training-f6f735830838" target="_blank"&gt;#2 Training&lt;/a&gt;, #3 Evaluation (this article), &lt;a href="https://medium.com/@adam5ny/machine-learning-tutorial-4-deployment-79764123e9e1" target="_blank"&gt;#4 Prediction&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Author website: &lt;a href="https://www.adamnovotny.com/" target="_blank"&gt;adamnovotny.com&lt;/a&gt;&lt;/p&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/blockquote&gt;
&lt;/blockquote&gt;</content><category term="Machine Learning"></category></entry><entry><title>Machine Learning Tutorial #2: Training</title><link href="https://adamnovotny.com/blog/machine-learning-tutorial-2-training.html" rel="alternate"></link><published>2018-08-12T00:00:00-05:00</published><updated>2018-08-12T00:00:00-05:00</updated><author><name>Adam Novotny</name></author><id>tag:adamnovotny.com,2018-08-12:/blog/machine-learning-tutorial-2-training.html</id><summary type="html">&lt;h4&gt;Topics: Performance Metrics, Cross Validation, Model Selection, Hyperparameter Optimization, Project Reflection, Tools&lt;/h4&gt;

&lt;p&gt;&lt;a href="/theme/images/1*iPgIcpnc-nzkigs6RaTZBw.png.png"&gt;&lt;img src="/theme/images/1*iPgIcpnc-nzkigs6RaTZBw.png.png" alt="Machine Learning project overview. Author: Adam Novotny" style="width: 100%" loading="lazy"&gt;&lt;/a&gt;
&lt;p&gt;This second part of the ML Tutorial follows up on the first &lt;a href="https://medium.com/@adam5ny/machine-learning-tutorial-1-preprocessing-d90198e37577" target="_blank"&gt;Preprocessing&lt;/a&gt; part. All code is available in this &lt;a href="https://github.com/adam5ny/blogs/tree/master/ml-training" target="_blank"&gt;Github repo&lt;/a&gt;. Other tutorials in this series: &lt;a href="https://medium.com/coinmonks/machine-learning-tutorial-1-preprocessing-d90198e37577" target="_blank"&gt;#1 Preprocessing&lt;/a&gt;, #2 Training (this article), &lt;a href="https://medium.com/@adam5ny/machine-learning-tutorial-3-evaluation-a157f90914c9" target="_blank"&gt;#3 Evaluation&lt;/a&gt; , &lt;a href="https://medium.com/@adam5ny/machine-learning-tutorial-4-deployment-79764123e9e1" target="_blank"&gt;#4 Prediction&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;I …&lt;/p&gt;&lt;/p&gt;</summary><content type="html">&lt;h4&gt;Topics: Performance Metrics, Cross Validation, Model Selection, Hyperparameter Optimization, Project Reflection, Tools&lt;/h4&gt;

&lt;p&gt;&lt;a href="/theme/images/1*iPgIcpnc-nzkigs6RaTZBw.png.png"&gt;&lt;img src="/theme/images/1*iPgIcpnc-nzkigs6RaTZBw.png.png" alt="Machine Learning project overview. Author: Adam Novotny" style="width: 100%" loading="lazy"&gt;&lt;/a&gt;
&lt;p&gt;This second part of the ML Tutorial follows up on the first &lt;a href="https://medium.com/@adam5ny/machine-learning-tutorial-1-preprocessing-d90198e37577" target="_blank"&gt;Preprocessing&lt;/a&gt; part. All code is available in this &lt;a href="https://github.com/adam5ny/blogs/tree/master/ml-training" target="_blank"&gt;Github repo&lt;/a&gt;. Other tutorials in this series: &lt;a href="https://medium.com/coinmonks/machine-learning-tutorial-1-preprocessing-d90198e37577" target="_blank"&gt;#1 Preprocessing&lt;/a&gt;, #2 Training (this article), &lt;a href="https://medium.com/@adam5ny/machine-learning-tutorial-3-evaluation-a157f90914c9" target="_blank"&gt;#3 Evaluation&lt;/a&gt; , &lt;a href="https://medium.com/@adam5ny/machine-learning-tutorial-4-deployment-79764123e9e1" target="_blank"&gt;#4 Prediction&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;I concluded Tutorial #1 with 4 datasets: training features, testing features, training target variables, and testing target variables. Only training features and and training target variables will be used in this Tutorial #2. The testing data will be used for evaluation purposes in Tutorial #3.&lt;/p&gt;
&lt;h4&gt;Performance Metrics&lt;/h4&gt;
&lt;p&gt;We are focused on regression algorithms so I will consider 3 most often used performance metrics&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Mean_absolute_error" target="_blank"&gt;Mean Absolute Error&lt;/a&gt; (MAE)&lt;/li&gt;&lt;/ul&gt;
&lt;ul&gt;&lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Mean_squared_error" target="_blank"&gt;Mean Squared Error&lt;/a&gt; (MSE)&lt;/li&gt;&lt;/ul&gt;
&lt;ul&gt;&lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Coefficient_of_determination" target="_blank"&gt;R²&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;p&gt;In practice, a domain-specific decision could be made to supplement the standard metrics above. For example, investors are typically more concerned about significant downside errors rather than upside errors. As a result, a metric could be derived that overemphasizes downside errors corresponding to financial losses.&lt;/p&gt;
&lt;h4&gt;Cross Validation&lt;/h4&gt;
&lt;p&gt;I will return to the same topic I addressed in &lt;a href="https://medium.com/@adam5ny/machine-learning-tutorial-1-preprocessing-d90198e37577" target="_blank"&gt;Preprocessing&lt;/a&gt;. Due to the nature of time series data, standard randomized K-fold validation produces forward looking bias and should not be used. To illustrate the issue here, let’s assume that we split 8 years of data into 8 folds, each representing one year. The first training cycle will use folds #1–7 for training and fold #8 for testing. The next training cycle may use folds #2–8 for training and fold #1 for testing. This is of course unacceptable because we are using data from years 2–7 to forecast year 1.&lt;/p&gt;
&lt;p&gt;Our cross validation must respect the temporal sequence of the data. We can use Walk Forward Validation or simply multiple Train-Test Splits. For illustration, I will use 3 Train-Test splits. For example, let’s assume we have 2000 samples sorted by timestamp from the earliest. Our 3 segments would look as follows:&lt;/p&gt;
&lt;a href="/theme/images/1*cFti5rqcbFrE5p_4My4eww.png.png"&gt;&lt;img src="/theme/images/1*cFti5rqcbFrE5p_4My4eww.png.png" alt="Train-Test splits. Author: Adam Novotny" style="width: 100%" loading="lazy"&gt;&lt;/a&gt;
&lt;h4&gt;Model Selection&lt;/h4&gt;
&lt;a href="/theme/images/1*M2clZWay68ODL2jEB-J5Dw.png.png"&gt;&lt;img src="/theme/images/1*M2clZWay68ODL2jEB-J5Dw.png.png" alt="ML Model Selection. Author: Adam Novotny" style="width: 100%" loading="lazy"&gt;&lt;/a&gt;
&lt;p&gt;In this section, I will select the models to train. The “Supervised” algorithms section (red section in the image above) is relevant because the dataset contains both features and labels (target variables). I like to follow &lt;a href="https://en.wikipedia.org/wiki/Occam%27s_razor" target="_blank"&gt;Occam’s razor&lt;/a&gt; when it comes to algorithms selection. In other words, start with the algorithm that exhibits the fastest times to train and the greatest interpretability. Then we can increase complexity.&lt;/p&gt;
&lt;p&gt;I will explore the following algorithms in this section:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Linear Regression: fast to learn, easy to interpret&lt;/li&gt;&lt;/ul&gt;
&lt;ul&gt;&lt;li&gt;Decision Trees: fast to learn (requires pruning), easy to interpret&lt;/li&gt;&lt;/ul&gt;
&lt;ul&gt;&lt;li&gt;Neural Networks: slow to learn, hard to interpret&lt;/li&gt;&lt;/ul&gt;
&lt;h4&gt;Linear Regression&lt;/h4&gt;
&lt;p&gt;Starting with linear regression is useful to see if we can “get away” with simple statistics to achieve our goal before diving into complex machine learning algorithms. House price forecasting with clearly defined features is an example where linear regression often works well and using more complex algorithms is unnecessary.&lt;/p&gt;
&lt;p&gt;Training a linear regression model using sklearn is simple:&lt;/p&gt;
&lt;pre&gt;from sklearn import linear_model
model = linear_model.LinearRegression()
model.fit(X_train, y_train)
y_pred = model.predict(X_test)&lt;/pre&gt;
&lt;p&gt;Initial results yielded nothing remotely promising so I took another step and transformed features further. I created polynomial and nonlinear features to account for nonlinear relationships. For example, features [a, b] become [1, a, b, a², ab, b²] in the case of degree-2 polynomial.&lt;/p&gt;
&lt;a href="/theme/images/1*c9-D9EJoTwKsRlJuK_WQaQ.png.png"&gt;&lt;img src="/theme/images/1*c9-D9EJoTwKsRlJuK_WQaQ.png.png" alt="Linear Regression results. Author: Adam Novotny" style="width: 100%" loading="lazy"&gt;&lt;/a&gt;
&lt;p&gt;The x-axis represents 3 cross validation segments (the fold 1st uses 1749 samples for training and 1749 for testing, the 2nd uses 3499 for training and 1749 for testing, and the last uses 5249 for training and 1749 for testing). Clearly, the results suggest that the linear model is not useful in practice. At this stage I have at least the following options:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Ridge regression: addresses overfitting (if any)&lt;/li&gt;&lt;/ul&gt;
&lt;ul&gt;&lt;li&gt;Lasso linear: reduces model complexity&lt;/li&gt;&lt;/ul&gt;
&lt;p&gt;At this point, I don’t believe that any of the options above will meaningfully impact the outcome. I will move on to other algorithms to see how they compare.&lt;/p&gt;
&lt;p&gt;Before moving on, however, I need to set expectations. There is a saying in finance that successful forecasters only need to be correct 51% of the time. Financial leverage can be used to magnify results so being just a little correct produces impactful outcomes. This sets expectations because we will never find algorithms that are constantly 60% correct or better in this domain. As a result, we expect low R² values. This needs to be said because many sample projects in machine learning are designed to look good, which we can never match in real-life price forecasting.&lt;/p&gt;
&lt;h4&gt;Decision Tree&lt;/h4&gt;
&lt;p&gt;Training a decision tree regressor model using sklearn is equally simple:&lt;/p&gt;
&lt;pre&gt;from sklearn import tree
model = tree.DecisionTreeRegressor()
model.fit(X_train, y_train)
y_pred = model.predict(X_test)&lt;/pre&gt;
&lt;p&gt;The default results for the fit function above almost always &lt;a href="https://en.wikipedia.org/wiki/Overfitting" target="_blank"&gt;overfit&lt;/a&gt;. Decision trees have a very expressive hypothesis space so they can represent almost any function when not pruned. R² for training data can easily become perfect 1.0 while for testing data the result will be 0. We therefore need to use the max_depth argument of scikit-learn &lt;a href="http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html#sklearn.tree.DecisionTreeRegressor" target="_blank"&gt;DecisionTreeRegressor&lt;/a&gt; to enforce that the tree generalizes well for test data.&lt;/p&gt;
&lt;p&gt;One of the biggest advantages of decision trees is their interpretability: see many useful &lt;a href="https://medium.com/@rnbrown/creating-and-visualizing-decision-trees-with-python-f8e8fa394176" target="_blank"&gt;visualization articles&lt;/a&gt; using standard illustrative datasets.&lt;/p&gt;
&lt;h4&gt;Neural Networks&lt;/h4&gt;
&lt;p&gt;Scikit-learn makes &lt;a href="http://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html#sklearn.neural_network.MLPRegressor" target="_blank"&gt;simple neural network&lt;/a&gt; training just as simple as building a decision tree:&lt;/p&gt;
&lt;pre&gt;from sklearn.neural_network import MLPRegressor
model = MLPRegressor(hidden_layer_sizes=(200, 200), solver="lbfgs", activation="relu")
model.fit(X_train, y_train)
y_pred = model.predict(X_test)&lt;/pre&gt;
&lt;p&gt;Training a neural net with 2 hidden layers (of 200 units each) and polynomial features starts taking tens of seconds on an average laptop. To speed up the training process in the next section, I will step away from scikit-learn and use &lt;a href="https://keras.io/" target="_blank"&gt;Keras&lt;/a&gt; with TensorFlow backend.&lt;/p&gt;
&lt;p&gt;Keras API is equally simple. The project even includes &lt;a href="https://keras.io/scikit-learn-api/#wrappers-for-the-scikit-learn-api" target="_blank"&gt;wrappers for scikit-learn&lt;/a&gt; to take advantage of scikit’s research libraries.&lt;/p&gt;
&lt;pre&gt;from keras.models import Sequential
from keras.layers import Dense
model = Sequential()
input_size = len(X[0])
model.add(Dense(200, activation="relu", input_dim=input_size))
model.add(Dense(200, activation="relu"))
model.add(Dense(1, activation="linear"))
model.compile(optimizer="adam", loss="mse")
model.fit(X_train, y_train, epochs=25, verbose=1)
y_pred = model.predict(X_test)&lt;/pre&gt;
&lt;h4&gt;Hyperparameter Optimization&lt;/h4&gt;
&lt;p&gt;The trick to doing hyperparameter optimization is to understand that parameters should not be treated independently. Many parameters interact with each other which is why exhaustive &lt;a href="https://en.wikipedia.org/wiki/Hyperparameter_optimization#Grid_search" target="_blank"&gt;grid search&lt;/a&gt; is often performed. However, grid search is that it becomes expensive very quickly.&lt;/p&gt;
&lt;h4&gt;Decision Tree&lt;/h4&gt;
&lt;p&gt;Our decision tree grid search will iterate over the following inputs:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;splitter: strategy used to split nodes (best or random)&lt;/li&gt;&lt;/ul&gt;
&lt;ul&gt;&lt;li&gt;max depth of the tree&lt;/li&gt;&lt;/ul&gt;
&lt;ul&gt;&lt;li&gt;min samples per split: the minimum number of samples required to split an internal node&lt;/li&gt;&lt;/ul&gt;
&lt;ul&gt;&lt;li&gt;max leaf nodes: number or None (allow unlimited number of leaf nodes)&lt;/li&gt;&lt;/ul&gt;
&lt;p&gt;Illustrative grid search results are below:&lt;/p&gt;
&lt;a href="/theme/images/1*CQHDbOr3_ZO7oWkdOYdKQw.png.png"&gt;&lt;img src="/theme/images/1*CQHDbOr3_ZO7oWkdOYdKQw.png.png" alt="Grid Search Decision Tree — first rows" style="width: 100%" loading="lazy"&gt;&lt;/a&gt;
&lt;a href="/theme/images/1*DQHZ9reWIOMF6fq9eKA8IQ.png.png"&gt;&lt;img src="/theme/images/1*DQHZ9reWIOMF6fq9eKA8IQ.png.png" alt="Grid Search Decision Tree — last rows" style="width: 100%" loading="lazy"&gt;&lt;/a&gt;
&lt;p&gt;Performance using the best parameters:&lt;/p&gt;
&lt;a href="/theme/images/1*2qHu4Z1DiJGmx440QCyTAA.png.png"&gt;&lt;img src="/theme/images/1*2qHu4Z1DiJGmx440QCyTAA.png.png" alt="Decision Tree results" style="width: 100%" loading="lazy"&gt;&lt;/a&gt;
&lt;p&gt;Again, the results do not seem to be very promising. They appear to be better than linear regression (lower MAE and MSE) but R² is still too low to be useful. I would conclude, however, that the greater expressiveness of decision trees is useful and I would discard the linear regression model at this stage.&lt;/p&gt;
&lt;h4&gt;Neural Networks&lt;/h4&gt;
&lt;p&gt;Exploring the hyperparameters of the neural net build by Keras, we can alter at least the following parameters:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;number of hidden layers and/or units in each layer&lt;/li&gt;&lt;/ul&gt;
&lt;ul&gt;&lt;li&gt;model &lt;a href="https://keras.io/optimizers/" target="_blank"&gt;optimizer&lt;/a&gt; (SGD, Adam, etc)&lt;/li&gt;&lt;/ul&gt;
&lt;ul&gt;&lt;li&gt;&lt;a href="https://keras.io/activations/" target="_blank"&gt;activation function&lt;/a&gt; in each layer (relu, tanh)&lt;/li&gt;&lt;/ul&gt;
&lt;ul&gt;&lt;li&gt;batch size: the number of samples per gradient update&lt;/li&gt;&lt;/ul&gt;
&lt;ul&gt;&lt;li&gt;epochs to train: the number of iterations over the entire training dataset&lt;/li&gt;&lt;/ul&gt;
&lt;p&gt;Illustrative grid search results are below:&lt;/p&gt;
&lt;a href="/theme/images/1*c_fhFAu5NkphQXM6Do8QXQ.png.png"&gt;&lt;img src="/theme/images/1*c_fhFAu5NkphQXM6Do8QXQ.png.png" alt="Grid Search Neural Net — first rows" style="width: 100%" loading="lazy"&gt;&lt;/a&gt;
&lt;a href="/theme/images/1*CZIYuZ9UrEdoVkWhOtfIWQ.png.png"&gt;&lt;img src="/theme/images/1*CZIYuZ9UrEdoVkWhOtfIWQ.png.png" alt="Grid Search Neural Net — last rows" style="width: 100%" loading="lazy"&gt;&lt;/a&gt;
&lt;p&gt;Using the best parameters, we obtain the following performance metrics:&lt;/p&gt;
&lt;a href="/theme/images/1*auWhs2uGbBher9adskreog.png.png"&gt;&lt;img src="/theme/images/1*auWhs2uGbBher9adskreog.png.png" alt="Keras MAE, MSE, R2" style="width: 100%" loading="lazy"&gt;&lt;/a&gt;
&lt;p&gt;Neural net and decision tree results are similar which is common. Both algorithms have very expressive hypothesis spaces and often produce comparable results. If I achieve comparable results, I tend to use the decision tree model for its faster training times and greater interpretability.&lt;/p&gt;
&lt;h4&gt;Project Reflection&lt;/h4&gt;
&lt;p&gt;At this stage it becomes clear that no model can be used in production. While the decision tree model appears to perform the best, its performance on testing data is still unreliable. At this stage, it would be time to go back and find additional features and/or data sources.&lt;/p&gt;
&lt;p&gt;As I mentioned in the first &lt;a href="https://medium.com/@adam5ny/machine-learning-tutorial-1-preprocessing-d90198e37577" target="_blank"&gt;Preprocessing Tutorial&lt;/a&gt;, finance practitioners might spend months sourcing data and building features. Domain-specific knowledge is crucial and I would argue that financial markets exhibit at least the &lt;a href="https://www.investopedia.com/exam-guide/cfa-level-1/securities-markets/weak-semistrong-strong-emh-efficient-market-hypothesis.asp" target="_blank"&gt;Weak-Form of Efficient Market Hypothesis&lt;/a&gt;. This implies that future stock returns cannot be predicted from past price movements. I have used only past price movements to develop the models above so practitioners would notice already in the first tutorial that results would not be promising.&lt;/p&gt;
&lt;p&gt;For the sake of completing this tutorial, I will go ahead and save the decision tree model and use it for illustrative purposes in the next sections of this tutorial (as if it were the Final production model):&lt;/p&gt;
&lt;pre&gt;pickle.dump(model, open("dtree_model.pkl", "wb"))&lt;/pre&gt;
&lt;p&gt;Important: there are &lt;a href="https://www.cs.uic.edu/~s/musings/pickle/" target="_blank"&gt;known security vulnerabilities&lt;/a&gt; in the Python pickle library. To stay on the safe side, the key takeaway is to never unpickle data you did not create.&lt;/p&gt;
&lt;h4&gt;Tools&lt;/h4&gt;
&lt;p&gt;Tooling is a common question but often not critical until the project is composed of tens of thousands of examples and at least hundreds of features. I typically start with scikit-learn and move elsewhere when performance becomes the bottleneck. &lt;a href="https://www.tensorflow.org/" target="_blank"&gt;TensorFlow&lt;/a&gt;, for example, is not just a deep learning framework but also contains other algorithms such as &lt;a href="https://www.tensorflow.org/api_docs/python/tf/estimator/LinearRegressor" target="_blank"&gt;LinearRegressor&lt;/a&gt;. We could train Linear Regression above with TensorFlow and GPUs if scikit-learn does not perform well enough.&lt;/p&gt;
&lt;p&gt;Other tutorials in this series: &lt;a href="https://medium.com/coinmonks/machine-learning-tutorial-1-preprocessing-d90198e37577" target="_blank"&gt;#1 Preprocessing&lt;/a&gt;, #2 Training (this article), &lt;a href="https://medium.com/@adam5ny/machine-learning-tutorial-3-evaluation-a157f90914c9" target="_blank"&gt;#3 Evaluation&lt;/a&gt; , &lt;a href="https://medium.com/@adam5ny/machine-learning-tutorial-4-deployment-79764123e9e1" target="_blank"&gt;#4 Prediction&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Author website: &lt;a href="https://www.adamnovotny.com/" target="_blank"&gt;adamnovotny.com&lt;/a&gt;&lt;/p&gt;&lt;/p&gt;</content><category term="Machine Learning"></category></entry><entry><title>Machine Learning Tutorial #1: Preprocessing</title><link href="https://adamnovotny.com/blog/machine-learning-tutorial-1-preprocessing.html" rel="alternate"></link><published>2018-08-05T00:00:00-05:00</published><updated>2018-08-05T00:00:00-05:00</updated><author><name>Adam Novotny</name></author><id>tag:adamnovotny.com,2018-08-05:/blog/machine-learning-tutorial-1-preprocessing.html</id><summary type="html">&lt;h4&gt;Topics: Data Cleaning, Target Variable Selection, Feature Extraction, Scaling, Dimensionality Reduction&lt;/h4&gt;

&lt;p&gt;In this machine learning tutorial, I will explore 4 steps that define a typical machine learning project: Preprocessing, Learning, Evaluation, and Prediction (deployment). In this first part, I will complete the Preprocessing step. Other tutorials in this series: #1 …&lt;/p&gt;</summary><content type="html">&lt;h4&gt;Topics: Data Cleaning, Target Variable Selection, Feature Extraction, Scaling, Dimensionality Reduction&lt;/h4&gt;

&lt;p&gt;In this machine learning tutorial, I will explore 4 steps that define a typical machine learning project: Preprocessing, Learning, Evaluation, and Prediction (deployment). In this first part, I will complete the Preprocessing step. Other tutorials in this series: #1 Preprocessing (this article), &lt;a href="https://medium.com/coinmonks/machine-learning-tutorial-2-training-f6f735830838" target="_blank"&gt;#2 Training&lt;/a&gt;, &lt;a href="https://medium.com/@adam5ny/machine-learning-tutorial-3-evaluation-a157f90914c9" target="_blank"&gt;#3 Evaluation&lt;/a&gt; , &lt;a href="https://medium.com/@adam5ny/machine-learning-tutorial-4-deployment-79764123e9e1" target="_blank"&gt;#4 Prediction&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href="/theme/images/1*iPgIcpnc-nzkigs6RaTZBw.png.png"&gt;&lt;img src="/theme/images/1*iPgIcpnc-nzkigs6RaTZBw.png.png" alt="Machine Learning project overview. Author: Adam Novotny" style="width: 100%" loading="lazy"&gt;&lt;/a&gt;
&lt;p&gt;I will use stock price data as the main dataset. There are a few reasons why this is a good choice for the tutorial:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;The dataset is public by definition and can be easily downloaded from multiple sources so anyone can replicate the work.&lt;/li&gt;&lt;/ul&gt;
&lt;ul&gt;&lt;li&gt;Not all features are immediately available from the source and need to be extracted using domain knowledge, resembling real life.&lt;/li&gt;&lt;/ul&gt;
&lt;ul&gt;&lt;li&gt;The outcome of the project is highly uncertain which again simulates real life. Billions of dollars are thrown at the stock price prediction problem every year and the vast majority of projects fail. This tutorial is therefore not about creating a magical money-printing machine; it is about replicating the experience a machine learning engineer might have with a project.&lt;/li&gt;&lt;/ul&gt;
&lt;p&gt;All code is located at the following &lt;a href="https://github.com/adam5ny/blogs/tree/master/ml-preprocessing" target="_blank"&gt;Github repo&lt;/a&gt;. The file “preprocessing.py” drives the analysis. Python 3.6 is recommended and the file includes directions to setup all necessary dependencies.&lt;/p&gt;
&lt;p&gt;First we need to download the dataset. I will somewhat arbitrarily choose the Microsoft stock data (source: &lt;a href="https://finance.yahoo.com/quote/MSFT/history?p=MSFT" target="_blank"&gt;Yahoo Finance&lt;/a&gt;). I will use the entire available history which at the time of writing includes 3/13/1986 — 7/30/2018. The share price performed as follows during this period:&lt;/p&gt;
&lt;a href="/theme/images/1*lR8eaHKYLjtKsZY_J19pog.png.png"&gt;&lt;img src="/theme/images/1*lR8eaHKYLjtKsZY_J19pog.png.png" alt="MSFT stock price. Source https://finance.yahoo.com/chart/MSFT" style="width: 100%" loading="lazy"&gt;&lt;/a&gt;
&lt;p&gt;The price movement is interesting because it exhibits at least two modes of behavior:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;the steep rise until the year 2000 when tech stocks crashed&lt;/li&gt;&lt;/ul&gt;
&lt;ul&gt;&lt;li&gt;the sideways movement since 2000&lt;/li&gt;&lt;/ul&gt;
&lt;p&gt;This makes for a number of interesting machine learning complexities such as the sampling of training and testing data.&lt;/p&gt;
&lt;h4&gt;Data Cleaning&lt;/h4&gt;
&lt;p&gt;After some simple manipulations and loading of the csv data into pandas DataFrame, we have the following dataset where open, high, low and close represent prices on each date and volume the total number of shares traded.&lt;/p&gt;
&lt;a href="/theme/images/1*psQ_9EoBHpiN78QgreAVOQ.png.png"&gt;&lt;img src="/theme/images/1*psQ_9EoBHpiN78QgreAVOQ.png.png" alt="Raw dataset includes columns: date, prices (open, high, low, close), trading volume" style="width: 100%" loading="lazy"&gt;&lt;/a&gt;
&lt;a href="/theme/images/1*pF4V5GC6b2vfC-koQkAynw.png.png"&gt;&lt;img src="/theme/images/1*pF4V5GC6b2vfC-koQkAynw.png.png" alt="Raw dataset includes columns: date, prices (open, high, low, close), trading volume" style="width: 100%" loading="lazy"&gt;&lt;/a&gt;
&lt;p&gt;Missing values are not present which I confirmed by running the following command:&lt;/p&gt;
&lt;pre&gt;missing_values_count = df.isnull().sum()&lt;/pre&gt;
&lt;a href="/theme/images/1*RxQtAFDbviXDbYcxU8j02Q.png.png"&gt;&lt;img src="/theme/images/1*RxQtAFDbviXDbYcxU8j02Q.png.png" alt="No missing values in dataset" style="width: 100%" loading="lazy"&gt;&lt;/a&gt;
&lt;p&gt;Outliers are the next topic I need to address. The key point to understand here is that our dataset now includes prices but prices are not the metric I will attempt to forecast because they are measured in absolute terms and therefore harder to compare across time and other assets. In the tables above, the first price available is ~$0.07 while the last is $105.37.&lt;/p&gt;
&lt;p&gt;Instead, I will attempt to forecast daily returns. For example, at the end of the second trading day the return was +3.6% (0.073673/0.071132). I will therefore create a return column and use it to analyze possible outliers.&lt;/p&gt;
&lt;p&gt;The 5 smallest daily returns present in the dataset are the following:&lt;/p&gt;
&lt;a href="/theme/images/1*-FluO_dSIB7Gc8Rlvgry_w.png.png"&gt;&lt;img src="/theme/images/1*-FluO_dSIB7Gc8Rlvgry_w.png.png" alt="5 smallest daily returns" style="width: 100%" loading="lazy"&gt;&lt;/a&gt;
&lt;p&gt;And 5 largest daily returns:&lt;/p&gt;
&lt;a href="/theme/images/1*CvJuQYGojLfLlxpnm9Ut1w.png.png"&gt;&lt;img src="/theme/images/1*CvJuQYGojLfLlxpnm9Ut1w.png.png" alt="5 largest daily returns" style="width: 100%" loading="lazy"&gt;&lt;/a&gt;
&lt;p&gt;The most negative return is -30% (index 405) and the largest is 20% (index 3692). Normally, a further domain-specific analysis of the outliers is necessary here. I will skip it for now and assume this tutorial outlines the process for illustrative purposes only. Generally, the data appears to make sense given that in 1987 and 2000 market crashes took place associated with extremely volatility.&lt;/p&gt;
&lt;p&gt;The same analysis would be required for open, high, low and volume columns. Admittedly, data cleaning was somewhat academic because Yahoo Finance is a very widely used and reliable source. It is still a useful exercise to understand the data.&lt;/p&gt;
&lt;h4&gt;Target Variable Selection&lt;/h4&gt;
&lt;p&gt;We need to define what our ML algorithms will attempt to forecast. Specifically, we will forecast next day’s return. The timing of returns is important here so we are not mistakenly forecasting today’s or yesterday’s return. The formula to define tomorrow’s return as our target variable is as follows:&lt;/p&gt;
&lt;pre&gt;df["y"] = df["return"].shift(-1)&lt;/pre&gt;
&lt;h4&gt;Feature Extraction&lt;/h4&gt;
&lt;p&gt;Now I will turn to some simple transformations of the prices, returns and volume to &lt;a href="https://en.wikipedia.org/wiki/Feature_extraction" target="_blank"&gt;extract features&lt;/a&gt; ML algorithms can consume. Finance practitioners have developed 100s of such features but I will only show a few. Hedge funds spent the vast majority of time on this step because ML algorithms are generally only as useful as the data available, aka. “garbage in, garbage out”.&lt;/p&gt;
&lt;p&gt;One feature we might consider is how today’s closing price relates to that of 5 trading days ago (one calendar week). I call this feature “5d_momentum”:&lt;/p&gt;
&lt;pre&gt;df[“5d_momentum”] = df[“close”] / df[“close”].shift(5)&lt;/pre&gt;
&lt;a href="/theme/images/1*4dWC4F1sqjmpW5dohmF-Mg.png.png"&gt;&lt;img src="/theme/images/1*4dWC4F1sqjmpW5dohmF-Mg.png.png" alt="New 5d_momentum feature" style="width: 100%" loading="lazy"&gt;&lt;/a&gt;
&lt;p&gt;One typical trend following feature is &lt;a href="https://stockcharts.com/school/doku.php?id=chart_school:technical_indicators:moving_average_convergence_divergence_macd" target="_blank"&gt;MACD&lt;/a&gt; (Moving Average Convergence/Divergence Oscillator). The strengths of pandas shine here because MACD can be created in only 4 lines of code. The chart of the MACD indicator is below. On the lower graph, a typical buy signal would be the blue “macd_line” crossing above the orange line representing a 9-day exponential moving average of the “macd_line”. The inverse would represent a sell signal.&lt;/p&gt;
&lt;a href="/theme/images/1*cA6MrDLu1Fuwd4pIDoS0fQ.png.png"&gt;&lt;img src="/theme/images/1*cA6MrDLu1Fuwd4pIDoS0fQ.png.png" alt="MACD of stock price" style="width: 100%" loading="lazy"&gt;&lt;/a&gt;
&lt;p&gt;The python code “generate_features.py” located in the Github repo mentioned above includes additional features we might consider. For example:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;a href="https://www.investopedia.com/articles/active-trading/052014/how-use-moving-average-buy-stocks.asp" target="_blank"&gt;Trend: Moving Average&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;a href="/theme/images/1*2ip_ErJJ73742mxoNoGknA.png.png"&gt;&lt;img src="/theme/images/1*2ip_ErJJ73742mxoNoGknA.png.png" alt="MSFT Moving Average 50 day — 200 day" style="width: 100%" loading="lazy"&gt;&lt;/a&gt;
&lt;ul&gt;&lt;li&gt;&lt;a href="https://stockcharts.com/school/doku.php?id=chart_school:technical_indicators:parabolic_sar" target="_blank"&gt;Trend: Parabolic SAR&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;a href="/theme/images/1*uRA6nhA4QpXoqhl6dfECrg.png.png"&gt;&lt;img src="/theme/images/1*uRA6nhA4QpXoqhl6dfECrg.png.png" alt="MSFT SAR" style="width: 100%" loading="lazy"&gt;&lt;/a&gt;
&lt;ul&gt;&lt;li&gt;&lt;a href="https://stockcharts.com/school/doku.php?id=chart_school:technical_indicators:stochastic_oscillator_fast_slow_and_full" target="_blank"&gt;Momentum: Stochastic Oscillator&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;a href="/theme/images/1*Qt0JrOJuvdUBelJ_ddGO1g.png.png"&gt;&lt;img src="/theme/images/1*Qt0JrOJuvdUBelJ_ddGO1g.png.png" alt="MSFT Stochastic Oscillator" style="width: 100%" loading="lazy"&gt;&lt;/a&gt;
&lt;ul&gt;&lt;li&gt;&lt;a href="https://stockcharts.com/school/doku.php?id=chart_school:technical_indicators:commodity_channel_index_cci" target="_blank"&gt;Momentum: Commodity Channel Index (CCI)&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;ul&gt;&lt;li&gt;&lt;a href="https://stockcharts.com/school/doku.php?id=chart_school:technical_indicators:relative_strength_index_rsi" target="_blank"&gt;Momentum: Relative Strength Index (RSI)&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;ul&gt;&lt;li&gt;&lt;a href="https://stockcharts.com/school/doku.php?id=chart_school:technical_indicators:bollinger_bands" target="_blank"&gt;Volatility: Bollinger Bands&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;ul&gt;&lt;li&gt;&lt;a href="https://stockcharts.com/school/doku.php?id=chart_school:technical_indicators:average_true_range_atr" target="_blank"&gt;Volatility: Average True Range&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;ul&gt;&lt;li&gt;&lt;a href="https://stockcharts.com/school/doku.php?id=chart_school:technical_indicators:on_balance_volume_obv" target="_blank"&gt;Volume: On Balance Volume (OBV)&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;ul&gt;&lt;li&gt;&lt;a href="https://stockcharts.com/school/doku.php?id=chart_school:technical_indicators:chaikin_oscillator" target="_blank"&gt;Volume: Chaikin Oscillator&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;p&gt;At the end of the feature extraction process, we have the following features:&lt;/p&gt;
&lt;pre&gt;['return', 'close_to_open', 'close_to_high', 'close_to_low', 'macd_diff', 'ma_50_200', 'sar', 'stochastic_oscillator', 'cci', 'rsi', '5d_volatility', '21d_volatility', '60d_volatility', 'bollinger', 'atr', 'on_balance_volume', 'chaikin_oscillator']&lt;/pre&gt;
&lt;h4&gt;Sampling&lt;/h4&gt;
&lt;p&gt;We need to split the data into training and testing buckets. I cannot stress enough that the testing dataset should never be used in the Learning step. It will be used only in the Evaluation step so that performance metrics are completely independent of training and represent an unbiased estimate of actual performance.&lt;/p&gt;
&lt;p&gt;Normally, we could randomize the sampling of testing data but time series data is often not well suited for randomized sampling. The reason being that would would bias the learning process. For example, randomization could produce a situation where the data point from 1/1/2005 is used in the Learning step to later forecast a return from 1/1/2003.&lt;/p&gt;
&lt;p&gt;I will therefore choose a much simpler way to sample the data and use the first 7000 samples as training dataset for Learning and the remaining 962 as testing dataset for Evaluation.&lt;/p&gt;
&lt;p&gt;Both datasets will be saved as csv files so we conclude this part of the ML tutorial by storing 4 files (MSFT_X_learn.csv, MSFT_y_learn.csv, MSFT_X_test.csv, MSFT_y_test.csv). These will be consumed by the next steps of this tutorial.&lt;/p&gt;
&lt;h4&gt;Scaling&lt;/h4&gt;
&lt;p&gt;Feature scaling is used to reduce the time to Learn. This typically applies to &lt;a href="https://en.wikipedia.org/wiki/Feature_scaling#Application" target="_blank"&gt;stochastic gradient descent and SMV&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The open source&lt;a href="http://scikit-learn.org/stable/index.html" target="_blank"&gt; sklearn&lt;/a&gt; package will be used for most additional ML application so I will start using it here to &lt;a href="http://scikit-learn.org/stable/modules/preprocessing.html#standardization-or-mean-removal-and-variance-scaling" target="_blank"&gt;scale all features&lt;/a&gt; to have zero mean and unit variance:&lt;/p&gt;
&lt;pre&gt;from sklearn import preprocessing
scaler_model = preprocessing.StandardScaler().fit(X_train)
X_train_scaled = scaler_model.transform(X_train)
X_test_scaled = scaler_model.transform(X_test)&lt;/pre&gt;
&lt;p&gt;It is important that data sampling takes place before features are modified to avoid any training to testing data leakage.&lt;/p&gt;
&lt;h4&gt;Dimensionality Reduction&lt;/h4&gt;
&lt;p&gt;At this stage, our dataset 17 features. The number of features has a significant impact on the speed of learning. We could use a number of techniques to try to reduce the number of features so that only the most “useful” features remain.&lt;/p&gt;
&lt;p&gt;Many hedge funds would be working with 100s of features at this stage so dimensional reduction would be critical. In our case, we only have 17 illustrative features so I will keep them all in the dataset until I explore the learning times of different algorithms.&lt;/p&gt;
&lt;p&gt;Out of curiosity however, I will perform Principal Component Analysis &lt;a href="http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html" target="_blank"&gt;(PCA) &lt;/a&gt;to get an idea of how many features we could create from our dataset without losing meaningful explanatory power.&lt;/p&gt;
&lt;pre&gt;from sklearn.decomposition import PCA
sk_model = PCA(n_components=10)
sk_model.fit_transform(features_ndarray)
print(sk_model.explained_variance_ratio_.cumsum())
 [0.30661571 0.48477408 0.61031358 0.71853895 0.78043556 0.83205298
 0.8764804  0.91533986 0.94022672 0.96216244]&lt;/pre&gt;
&lt;p&gt;The first 8 features explain 91.5% of data variance. The downside of PCA is that new features are located in a lower dimensional space so they no longer correspond the real-life concepts. For example, the first original feature could be “macd_line” I derived above. After PCA, the first feature explains 31% of variance but we not longer have any logical description for what the feature represents in real life.&lt;/p&gt;
&lt;p&gt;For now, I will keep all features 17 original features but note that if the learning time of algorithms is too slow, PCA will be helpful.&lt;/p&gt;
&lt;p&gt;Other tutorials in this series: #1 Preprocessing (this article), &lt;a href="https://medium.com/coinmonks/machine-learning-tutorial-2-training-f6f735830838" target="_blank"&gt;#2 Training&lt;/a&gt;, &lt;a href="https://medium.com/@adam5ny/machine-learning-tutorial-3-evaluation-a157f90914c9" target="_blank"&gt;#3 Evaluation&lt;/a&gt; , &lt;a href="https://medium.com/@adam5ny/machine-learning-tutorial-4-deployment-79764123e9e1" target="_blank"&gt;#4 Prediction&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Author website: &lt;a href="https://www.adamnovotny.com/" target="_blank"&gt;adamnovotny.com&lt;/a&gt;&lt;/p&gt;&lt;/p&gt;</content><category term="Machine Learning"></category></entry></feed>