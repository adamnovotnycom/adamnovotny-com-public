<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>ANotes</title><link>https://adamnovotny.com/</link><description></description><lastBuildDate>Sat, 22 Mar 2025 00:00:00 -0500</lastBuildDate><item><title>Large Language Models (LLMs) Notes</title><link>https://adamnovotny.com/blog/llm.html</link><description>&lt;h4&gt;Contents&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#architecture"&gt;Architecture&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#papers"&gt;Papers&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#overview"&gt;Overviews&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;Architecture &lt;span id="architecture"&gt;&lt;/span&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://bbycroft.net/llm"&gt;LLM visualization&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;Papers &lt;span id="papers"&gt;&lt;/span&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://adamnovotny.com/theme/documents/Attention_Is_All_You%20Need.pdf"&gt;Attention Is All You Need&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;Overview &lt;span id="overview"&gt;&lt;/span&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Deep Dive into LLMs like ChatGPT by Andrej Karpathy (Summary) &lt;a href="https://youtu.be/7xTGNNLPyMI?feature=shared&amp;t=12107"&gt;Youtube&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=zjkBMFhNj_g"&gt;Intro to Large Language Models by Andrej Karpathy&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Adam Novotny</dc:creator><pubDate>Sat, 22 Mar 2025 00:00:00 -0500</pubDate><guid isPermaLink="false">tag:adamnovotny.com,2025-03-22:/blog/llm.html</guid><category>Machine Learning</category></item><item><title>AI / Machine Learning Notes</title><link>https://adamnovotny.com/blog/machine-learning-notes.html</link><description>&lt;h4&gt;Contents&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#algorithms"&gt;Algorithms&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#bayes"&gt;Bayes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#explainability"&gt;Explainability&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#mlops"&gt;MLOps&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#model_evaluation"&gt;Model Evaluation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#preprocessing"&gt;Preprocessing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#reinforcement_learning"&gt;Reinforcement Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#sql"&gt;SQL&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#statistics"&gt;Statistics&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;Algorithms &lt;span id="algorithms"&gt;&lt;/span&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;K-means: aims to choose centroids that minimize the inertia, or within-cluster sum-of-squares criterion. Use the &lt;a href="https://www.scikit-yb.org/en/latest/api/cluster/elbow.html"&gt;“elbow” method&lt;/a&gt; to identify the right number of means. &lt;a href="https://scikit-learn.org/stable/modules/clustering.html#k-means"&gt;scikit tutorial&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;KNN: Simple, flexible, naturally handles multiple classes. Slow at scale, sensitive …&lt;/li&gt;&lt;/ul&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Adam Novotny</dc:creator><pubDate>Sat, 22 Feb 2025 00:00:00 -0500</pubDate><guid isPermaLink="false">tag:adamnovotny.com,2025-02-22:/blog/machine-learning-notes.html</guid><category>Machine Learning</category></item><item><title>Deploying Language Models With Gradio On Hugging Face</title><link>https://adamnovotny.com/blog/deploying-language-models-with-gradio-on-huggingface.html</link><description>&lt;p&gt;Machine learning models (including language models) can be easily deployed using generous &lt;a href="https://huggingface.co/pricing#spaces"&gt;free tier on Hugging Face&lt;/a&gt; and a python-based open source UI tool &lt;a href="https://www.gradio.app/guides/quickstart"&gt;Gradio&lt;/a&gt; by following these steps.&lt;/p&gt;
&lt;p&gt;See live deployed app and source code &lt;a href="https://huggingface.co/spaces/AdamNovotnyCom/llama2-gradio-huggingface"&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;For local development, create the &lt;a href="https://huggingface.co/spaces/AdamNovotnyCom/llama2-gradio-huggingface/blob/main/Dockerfile_dev"&gt;following Dockerfile&lt;/a&gt;. It differs from production Dockerfile in …&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Adam Novotny</dc:creator><pubDate>Sat, 14 Oct 2023 00:00:00 -0500</pubDate><guid isPermaLink="false">tag:adamnovotny.com,2023-10-14:/blog/deploying-language-models-with-gradio-on-huggingface.html</guid><category>Machine Learning</category></item><item><title>Machine Learning Docker Template</title><link>https://adamnovotny.com/blog/machine-learning-docker-template.html</link><description>&lt;h3&gt;Contents&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#summary"&gt;Summary&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#code"&gt;Code&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Summary &lt;span id="summary"&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;The purpose of this post is to propose a template for machine learning projects that strives to follow these principles:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;All data scientists can quickly setup an identical development environment based on Docker that encourages good software engineering practices.&lt;/li&gt;
&lt;li&gt;Dependency management is handled during the environment's …&lt;/li&gt;&lt;/ol&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Adam Novotny</dc:creator><pubDate>Sat, 18 Dec 2021 00:00:00 -0500</pubDate><guid isPermaLink="false">tag:adamnovotny.com,2021-12-18:/blog/machine-learning-docker-template.html</guid><category>Machine Learning</category></item><item><title>Keras LSTM Forecasting Using Synthetic Data</title><link>https://adamnovotny.com/blog/lstm-forecast-synthetic-data.html</link><description>&lt;h3&gt;Contents&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#summary"&gt;Summary&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#notebook"&gt;Notebook&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Summary &lt;span id="summary"&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;Keras LSTM can be a powerful tool for forecasting. Below is a simple template notebook showing how to setup a data science forecasting experiment.&lt;/p&gt;
&lt;h4&gt;Dataset&lt;/h4&gt;
&lt;p&gt;A synthetic dataset was generated using a scikit-learn regression generator &lt;a href="https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_friedman1.html#sklearn.datasets.make_friedman1" target="_blank"&gt;make_friedman1&lt;/a&gt;. The dataset is nonlinear, with noise, and some features are …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Adam Novotny</dc:creator><pubDate>Sat, 13 Nov 2021 00:00:00 -0500</pubDate><guid isPermaLink="false">tag:adamnovotny.com,2021-11-13:/blog/lstm-forecast-synthetic-data.html</guid><category>Machine Learning</category></item><item><title>Scikit-learn Pipeline with Feature Engineering</title><link>https://adamnovotny.com/blog/custom-scikit-learn-pipeline.html</link><description>&lt;h4&gt;Contents&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="#summary"&gt;Summary&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#notebook"&gt;Notebook&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id="summary"&gt;Summary&lt;/h4&gt;
&lt;p&gt;In general, a machine learning pipeline should have the following characteristics:&lt;/p&gt;
&lt;p&gt;&lt;a href="/theme/images/1*8PUAA9DjMv6CMsPWhbayIQ.png.png"&gt;&lt;img src="/theme/images/1*8PUAA9DjMv6CMsPWhbayIQ.png.png" alt="scikit-learn logo" style="width: 50%" loading="lazy"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
    &lt;li&gt;To ensure data consistency, the pipeline should include every step (such as feature engineering) required to train and score training and testing datasets, and score real time requests. The pipeline does not need to include …&lt;/li&gt;&lt;/ul&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Adam Novotny</dc:creator><pubDate>Mon, 30 Aug 2021 00:00:00 -0500</pubDate><guid isPermaLink="false">tag:adamnovotny.com,2021-08-30:/blog/custom-scikit-learn-pipeline.html</guid><category>Machine Learning</category></item><item><title>Global Temperature Forecast Using Prophet and CO2</title><link>https://adamnovotny.com/blog/berkeley-global-temperature-forecast-prophet.html</link><description>&lt;p&gt;
In this article I will leverage the global &lt;a href="https://adamnovotny.com/blog/berkeley-earth-global-temperature-data2.html"&gt;temperate dataset I discussed previously&lt;/a&gt; to make a temperature forecast using &lt;a href="https://facebook.github.io/prophet/"&gt;Facebook Prophet&lt;/a&gt; for the next 50 years. Note: the temperature dataset serves ONLY as a vehicle to learn how to do forecasting using Prophet. In general, climate and other complex sciences …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Adam Novotny</dc:creator><pubDate>Sun, 16 May 2021 00:00:00 -0500</pubDate><guid isPermaLink="false">tag:adamnovotny.com,2021-05-16:/blog/berkeley-global-temperature-forecast-prophet.html</guid><category>Machine Learning</category></item><item><title>Berkeley Earth Global Temperature Data</title><link>https://adamnovotny.com/blog/berkeley-earth-global-temperature-data2.html</link><description>&lt;p&gt;&lt;a href="http://berkeleyearth.org/data/"&gt;Berkeley Earth&lt;/a&gt; publishes an unique dataset with global temperature measurements. Below is a guide to the download the data and start analyzing it using Python. All code can be found in this &lt;a href="https://gist.github.com/adamnovotnycom/e844fbfdbcc563123cbbfcd96604bb7b"&gt;gist&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;a href="/theme/images/pztgdtmbiuigjqxlyuejjkjmprukqdkbjqvcbdc.png"&gt;&lt;img style="width: 100%" loading="lazy"  alt="Berkeley Earth air temperature measurements above sea ice" src="/theme/images/pztgdtmbiuigjqxlyuejjkjmprukqdkbjqvcbdc.png"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Download .txt file from &lt;a href="http://berkeleyearth.org/data/"&gt;Berkeley Earth&lt;/a&gt; data website section "Land + Ocean (1850 — Recent)" and read it using …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Adam Novotny</dc:creator><pubDate>Fri, 14 May 2021 00:00:00 -0500</pubDate><guid isPermaLink="false">tag:adamnovotny.com,2021-05-14:/blog/berkeley-earth-global-temperature-data2.html</guid><category>Random</category></item><item><title>Dynamic HTML with Python, AWS Lambda, and Containers</title><link>https://adamnovotny.com/blog/dynamic-html-with-python-aws-lambda-and-containers.html</link><description>&lt;p&gt;This article is an extension of my previous article describing a similar &lt;a href="https://adamnovotny.com/blog/serving-dynamic-web-pages-using-python-and-aws-lambda.html" target="_blank"&gt;deployment process using native AWS Lambda tools&lt;/a&gt;. However, Amazon since started &lt;a href="https://aws.amazon.com/blogs/aws/new-for-aws-lambda-container-image-support/" target="_blank"&gt;supporting container images&lt;/a&gt; and updated it’s pricing policy to &lt;a href="https://aws.amazon.com/blogs/aws/new-for-aws-lambda-1ms-billing-granularity-adds-cost-savings/" target="_blank"&gt;1ms granularity&lt;/a&gt;. Both are major developments improving tooling and making small deployments cost effective.&lt;/p&gt;
&lt;p&gt;&lt;a href="/theme/images/1*WSpeFmskKx0xiwx-WRRJ6A.jpeg.png"&gt;&lt;img src="/theme/images/1*WSpeFmskKx0xiwx-WRRJ6A.jpeg.png" alt="Deploying AWS Lambda using a container" style="width: 100%" loading="lazy"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;My &lt;a href="https://adamnovotny.com/blog/serving-dynamic-web-pages-using-python-and-aws-lambda.html" target="_blank"&gt;previous&lt;/a&gt; article …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Adam Novotny</dc:creator><pubDate>Sat, 27 Mar 2021 00:00:00 -0500</pubDate><guid isPermaLink="false">tag:adamnovotny.com,2021-03-27:/blog/dynamic-html-with-python-aws-lambda-and-containers.html</guid><category>Machine Learning</category></item><item><title>Google Colab and Auto-sklearn with Profiling</title><link>https://adamnovotny.com/blog/google-colab-and-auto-sklearn-with-profiling.html</link><description>&lt;p&gt;This article is a follow up to my previous tutorial on how to &lt;a href="https://adamnovotny.com/blog/google-colab-and-automl-auto-sklearn-setup.html" target="_blank"&gt;setup Google Colab and auto-sklean&lt;/a&gt;. Here, I will go into more detail that shows auto-sklearn performance on an artificially created dataset. The full notebook gist can be found &lt;a href="https://gist.github.com/adamnovotnycom/ffe8e3961fe0207c64a1b9a074883e51" target="_blank"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;First, I generated a regression dataset using &lt;a href="https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_regression.html" target="_blank"&gt;scikit …&lt;/a&gt;&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Adam Novotny</dc:creator><pubDate>Sat, 20 Mar 2021 00:00:00 -0500</pubDate><guid isPermaLink="false">tag:adamnovotny.com,2021-03-20:/blog/google-colab-and-auto-sklearn-with-profiling.html</guid><category>Machine Learning</category></item><item><title>Google Colab and AutoML: Auto-sklearn Setup</title><link>https://adamnovotny.com/blog/google-colab-and-automl-auto-sklearn-setup.html</link><description>&lt;p&gt;Auto ML is fast becoming a popular solution to build minimal viable models for new projects. A popular library for Python is &lt;a href="https://automl.github.io/auto-sklearn/master/#" target="_blank"&gt;Auto-sklearn&lt;/a&gt; that leverages the most popular Python ML library &lt;a href="http://sklearn.org" target="_blank"&gt;scikit-learn&lt;/a&gt;. Auto-sklearn runs a smart search over scikit-learn models and parameters to find the best performing ensemble of models …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Adam Novotny</dc:creator><pubDate>Fri, 04 Dec 2020 00:00:00 -0500</pubDate><guid isPermaLink="false">tag:adamnovotny.com,2020-12-04:/blog/google-colab-and-automl-auto-sklearn-setup.html</guid><category>Machine Learning</category></item><item><title>Google Paper: 24/7 by 2030</title><link>https://adamnovotny.com/blog/google-paper-24-7-by-2030.html</link><description>&lt;p&gt;Google released a &lt;a href="https://www.gstatic.com/gumdrop/sustainability/247-carbon-free-energy.pdf" target="_blank"&gt;white paper&lt;/a&gt; describing how the company intends to generate all of its electricity needs from renewable energy sources by 2030. Previously, Google committed to reducing emissions by buying offsets or generating renewable energy off-cycle. This new commitment goes by further: “Google intends to match its operational electricity …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Adam Novotny</dc:creator><pubDate>Sat, 31 Oct 2020 00:00:00 -0500</pubDate><guid isPermaLink="false">tag:adamnovotny.com,2020-10-31:/blog/google-paper-24-7-by-2030.html</guid><category>Random</category></item><item><title>Serving Dynamic Web Pages using Python and AWS Lambda</title><link>https://adamnovotny.com/blog/serving-dynamic-web-pages-using-python-and-aws-lambda.html</link><description>&lt;p&gt;While AWS Lambda functions are typically used to build API endpoints, at their core Lambda functions can return almost anything. This includes returning html markup with dynamic content.&lt;/p&gt;
&lt;p&gt;&lt;a href="/theme/images/1*9bPdHLV7ghV1RuNYOGkTvA.png.png"&gt;&lt;img src="/theme/images/1*9bPdHLV7ghV1RuNYOGkTvA.png.png" alt="AWS Lambda + Python + Jinja" style="width: 100%" loading="lazy"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;I will not go into details describing how to deploy AWS Lambda functions. Please see the official &lt;a href="https://docs.aws.amazon.com/lambda/latest/dg/lambda-python.html" target="_blank"&gt;documentation&lt;/a&gt;. I will however describe …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Adam Novotny</dc:creator><pubDate>Sat, 25 Jul 2020 00:00:00 -0500</pubDate><guid isPermaLink="false">tag:adamnovotny.com,2020-07-25:/blog/serving-dynamic-web-pages-using-python-and-aws-lambda.html</guid><category>Machine Learning</category></item><item><title>Custom VPN using PiVPN and public cloud</title><link>https://adamnovotny.com/blog/custom-vpn-using-pivpn-and-public-cloud.html</link><description>&lt;p&gt;Motivation: Many public Wi-Fi networks block certain internet ports and protocols. For example, a public library might only allow ports 80 and 443 and the TCP protocol. Leaving aside the logic of such decisions by network owners, they prevent users from taking advantage of many commercial VPN products that rely …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Adam Novotny</dc:creator><pubDate>Sun, 30 Dec 2018 00:00:00 -0500</pubDate><guid isPermaLink="false">tag:adamnovotny.com,2018-12-30:/blog/custom-vpn-using-pivpn-and-public-cloud.html</guid><category>Machine Learning</category></item><item><title>Serverless web apps with Firebase and AWS Lambda</title><link>https://adamnovotny.com/blog/serverless-web-apps-with-firebase-and-aws-lambda.html</link><description>&lt;p&gt;Serverless has become a popular solution for small to medium-sized projects. The downside is a technology stack lock-in which forces developers to use technologies that might not be optimal for their projects. For example, people using &lt;a href="https://firebase.google.com/" target="_blank"&gt;Google’s Firebase&lt;/a&gt; to host their static resources have to write custom endpoint &lt;a href="https://firebase.google.com/docs/functions/" target="_blank"&gt;functions …&lt;/a&gt;&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Adam Novotny</dc:creator><pubDate>Sun, 09 Sep 2018 00:00:00 -0500</pubDate><guid isPermaLink="false">tag:adamnovotny.com,2018-09-09:/blog/serverless-web-apps-with-firebase-and-aws-lambda.html</guid><category>Machine Learning</category></item><item><title>Machine Learning Tutorial #4: Deployment</title><link>https://adamnovotny.com/blog/machine-learning-tutorial-4-deployment.html</link><description>&lt;p&gt;&lt;a href="/theme/images/1*T_-rIQ8yUgPba_ezxt6ogg.png.png"&gt;&lt;img src="/theme/images/1*T_-rIQ8yUgPba_ezxt6ogg.png.png" alt="Machine Learning project overview. Author: Adam Novotny" style="width: 100%" loading="lazy"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;In this final phase of the series, I will suggest a few options ML engineers have to deploy their code. In large organizations, this part of the project will be handled by a specialized team which is especially important when scaling is a concern. Other tutorials in this series: &lt;a href="https://medium.com/coinmonks/machine-learning-tutorial-1-preprocessing-d90198e37577" target="_blank"&gt;#1 …&lt;/a&gt;&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Adam Novotny</dc:creator><pubDate>Sun, 02 Sep 2018 00:00:00 -0500</pubDate><guid isPermaLink="false">tag:adamnovotny.com,2018-09-02:/blog/machine-learning-tutorial-4-deployment.html</guid><category>Machine Learning</category></item><item><title>Machine Learning Tutorial #3: Evaluation</title><link>https://adamnovotny.com/blog/machine-learning-tutorial-3-evaluation.html</link><description>&lt;p&gt;&lt;a href="/theme/images/1*iPgIcpnc-nzkigs6RaTZBw.png.png"&gt;&lt;img src="/theme/images/1*iPgIcpnc-nzkigs6RaTZBw.png.png" alt="Machine Learning project overview. Author: Adam Novotny" style="width: 100%" loading="lazy"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;In this third phase of the series, I will explore the Evaluation part of the ML project. I will reuse some of the code and solutions from the second Training phase. However, it is important to note that the Evaluation phase should be completely separate from training except for using …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Adam Novotny</dc:creator><pubDate>Sun, 19 Aug 2018 00:00:00 -0500</pubDate><guid isPermaLink="false">tag:adamnovotny.com,2018-08-19:/blog/machine-learning-tutorial-3-evaluation.html</guid><category>Machine Learning</category></item><item><title>Machine Learning Tutorial #2: Training</title><link>https://adamnovotny.com/blog/machine-learning-tutorial-2-training.html</link><description>&lt;p&gt;&lt;a href="/theme/images/1*iPgIcpnc-nzkigs6RaTZBw.png.png"&gt;&lt;img src="/theme/images/1*iPgIcpnc-nzkigs6RaTZBw.png.png" alt="Machine Learning project overview. Author: Adam Novotny" style="width: 100%" loading="lazy"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This second part of the ML Tutorial follows up on the first &lt;a href="https://medium.com/@adam5ny/machine-learning-tutorial-1-preprocessing-d90198e37577" target="_blank"&gt;Preprocessing&lt;/a&gt; part. All code is available in this &lt;a href="https://github.com/adam5ny/blogs/tree/master/ml-training" target="_blank"&gt;Github repo&lt;/a&gt;. Other tutorials in this series: &lt;a href="https://medium.com/coinmonks/machine-learning-tutorial-1-preprocessing-d90198e37577" target="_blank"&gt;#1 Preprocessing&lt;/a&gt;, #2 Training (this article), &lt;a href="https://medium.com/@adam5ny/machine-learning-tutorial-3-evaluation-a157f90914c9" target="_blank"&gt;#3 Evaluation&lt;/a&gt; , &lt;a href="https://medium.com/@adam5ny/machine-learning-tutorial-4-deployment-79764123e9e1" target="_blank"&gt;#4 Prediction&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;I concluded Tutorial #1 with 4 datasets: training features, testing features, training target …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Adam Novotny</dc:creator><pubDate>Sun, 12 Aug 2018 00:00:00 -0500</pubDate><guid isPermaLink="false">tag:adamnovotny.com,2018-08-12:/blog/machine-learning-tutorial-2-training.html</guid><category>Machine Learning</category></item><item><title>Machine Learning Tutorial #1: Preprocessing</title><link>https://adamnovotny.com/blog/machine-learning-tutorial-1-preprocessing.html</link><description>&lt;p&gt;In this machine learning tutorial, I will explore 4 steps that define a typical machine learning project: Preprocessing, Learning, Evaluation, and Prediction (deployment). In this first part, I will complete the Preprocessing step. Other tutorials in this series: #1 Preprocessing (this article), &lt;a href="https://medium.com/coinmonks/machine-learning-tutorial-2-training-f6f735830838" target="_blank"&gt;#2 Training&lt;/a&gt;, &lt;a href="https://medium.com/@adam5ny/machine-learning-tutorial-3-evaluation-a157f90914c9" target="_blank"&gt;#3 Evaluation&lt;/a&gt; , &lt;a href="https://medium.com/@adam5ny/machine-learning-tutorial-4-deployment-79764123e9e1" target="_blank"&gt;#4 Prediction&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="/theme/images/1*iPgIcpnc-nzkigs6RaTZBw.png.png"&gt;&lt;img src="/theme/images/1*iPgIcpnc-nzkigs6RaTZBw.png.png" alt="Machine Learning project overview. Author: Adam Novotny" style="width: 100%" loading="lazy"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;I will …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Adam Novotny</dc:creator><pubDate>Sun, 05 Aug 2018 00:00:00 -0500</pubDate><guid isPermaLink="false">tag:adamnovotny.com,2018-08-05:/blog/machine-learning-tutorial-1-preprocessing.html</guid><category>Machine Learning</category></item><item><title>Linear programming in Python: CVXOPT and game theory</title><link>https://adamnovotny.com/blog/linear-programming-in-python-cvxopt-and-game-theory.html</link><description>&lt;p&gt;CVXOPT is an excellent Python package for linear programming. However, when I was getting started with it, I spent way too much time getting it to work with simple game theory example problems. This tutorial aims to shorten the startup time for everyone trying to use CVXOPT for more advanced …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Adam Novotny</dc:creator><pubDate>Wed, 16 Aug 2017 00:00:00 -0500</pubDate><guid isPermaLink="false">tag:adamnovotny.com,2017-08-16:/blog/linear-programming-in-python-cvxopt-and-game-theory.html</guid><category>Machine Learning</category></item></channel></rss>